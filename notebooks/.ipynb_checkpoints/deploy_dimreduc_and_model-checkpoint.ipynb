{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, codecs\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from collections import defaultdict\n",
    "import string\n",
    "from string import punctuation\n",
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THESE SHOULD BE ALL THE RELATIVE PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_dir = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs_dir = '/home/ubuntu/Capstone/outputs/ec2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class IterFile(object):\n",
    "    '''\n",
    "    class object to do the iterating on individual book txt documents, including file i/o.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = filepath\n",
    "        \n",
    "    def _open_file(self):\n",
    "        self.file = codecs.open(self.filepath, 'r', encoding='utf_8')\n",
    "        \n",
    "    def _close_file(self):\n",
    "        self.file.close()\n",
    "    \n",
    "    def __iter__(self):\n",
    "        '''\n",
    "        overwrite iteration to include file i/o\n",
    "        '''\n",
    "        self._open_file()\n",
    "        \n",
    "        for line in self.file:\n",
    "            yield line\n",
    "        \n",
    "        self._close_file()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transform_txt_file_v1(fname, root=source_dir):\n",
    "    '''\n",
    "    Initial pass at text transformation\n",
    "    Reimplemented later (v2 etc) as a caller of various subfunctions to do all the transformation\n",
    "    '''\n",
    "    fp = root + fname\n",
    "\n",
    "    book_as_lst = []\n",
    "    for line in IterFile(fp):\n",
    "        if line == \"\\n\":\n",
    "            pass\n",
    "        else: \n",
    "            line_lst= [tok.lower().strip(punctuation) for tok in line.strip('\\n').split()]\n",
    "            book_as_lst.extend(line_lst)\n",
    "            \n",
    "    #add in stop word removal and frequency threshhold\n",
    "    return book_as_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10-clean.txt',\n",
       " '100-clean.txt',\n",
       " '105-clean.txt',\n",
       " '108-clean.txt',\n",
       " '1080-clean.txt',\n",
       " '11-clean.txt',\n",
       " '1112-clean.txt',\n",
       " '1184-clean.txt',\n",
       " '12-clean.txt',\n",
       " '120-clean.txt',\n",
       " '1232-clean.txt',\n",
       " '1260-clean.txt',\n",
       " '1322-clean.txt',\n",
       " '1342-clean.txt',\n",
       " '135-clean.txt',\n",
       " '1399-clean.txt',\n",
       " '140-clean.txt',\n",
       " '1400-clean.txt',\n",
       " '1404-clean.txt',\n",
       " '14264-clean.txt',\n",
       " '147-clean.txt',\n",
       " '1497-clean.txt',\n",
       " '15399-clean.txt',\n",
       " '158-clean.txt',\n",
       " '16-clean.txt',\n",
       " '160-clean.txt',\n",
       " '161-clean.txt',\n",
       " '16382-clean.txt',\n",
       " '1661-clean.txt',\n",
       " '1727-clean.txt',\n",
       " '174-clean.txt',\n",
       " '1952-yellow_wallpaper-clean.txt',\n",
       " '19942-clean.txt',\n",
       " '20-clean.txt',\n",
       " '20203-clean.txt',\n",
       " '203-clean.txt',\n",
       " '205-clean.txt',\n",
       " '21279-clean.txt',\n",
       " '2148-clean.txt',\n",
       " '2174-clean.txt',\n",
       " '219-clean.txt',\n",
       " '224-clean.txt',\n",
       " '23-clean.txt',\n",
       " '236-clean.txt',\n",
       " '2500-clean.txt',\n",
       " '25305-clean.txt',\n",
       " '2591-clean.txt',\n",
       " '2600-clean.txt',\n",
       " '2680-clean.txt',\n",
       " '2701-moby-clean.txt',\n",
       " '28054-clean.txt',\n",
       " '2814-clean.txt',\n",
       " '2852-clean.txt',\n",
       " '28520-clean.txt',\n",
       " '30360-clean.txt',\n",
       " '30601-clean.txt',\n",
       " '3207-clean.txt',\n",
       " '33-clean.txt',\n",
       " '33283-clean.txt',\n",
       " '345-clean.txt',\n",
       " '34901-clean.txt',\n",
       " '35-clean.txt',\n",
       " '36-clean.txt',\n",
       " '3600-clean.txt',\n",
       " '38427-clean.txt',\n",
       " '408-clean.txt',\n",
       " '41-clean.txt',\n",
       " '42-clean.txt',\n",
       " '4300-clean.txt',\n",
       " '4363-clean.txt',\n",
       " '45-clean.txt',\n",
       " '4517-clean.txt',\n",
       " '46-clean.txt',\n",
       " '514-clean.txt',\n",
       " '5200-clean.txt',\n",
       " '521-clean.txt',\n",
       " '526-clean.txt',\n",
       " '55-clean.txt',\n",
       " '55387-clean.txt',\n",
       " '55404-clean.txt',\n",
       " '6130-clean.txt',\n",
       " '730-clean.txt',\n",
       " '7370-clean.txt',\n",
       " '74-clean.txt',\n",
       " '76-clean.txt',\n",
       " '768-clean.txt',\n",
       " '829-clean.txt',\n",
       " '84-clean.txt',\n",
       " '844-clean.txt',\n",
       " '851-clean.txt',\n",
       " '863-clean.txt',\n",
       " '8800-clean.txt',\n",
       " '932-clean.txt',\n",
       " '98-clean.txt',\n",
       " '996-clean.txt']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_corp = PlaintextCorpusReader(source_dir, '.*\\.txt')\n",
    "fileid_lst = temp_corp.fileids()\n",
    "fileid_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA and Saving helper funtions\n",
    "\n",
    "To automate EDA steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def eda(transform_txt_file, fileid_lst=fileid_lst):\n",
    "    '''\n",
    "    Do transformations with updated transformation function and return all the eda items\n",
    "    '''\n",
    "    \n",
    "    all_transf_books_lst = [transform_txt_file(f) for f in fileid_lst]\n",
    "    \n",
    "    book_lengths = [(tup[0], len(tup[1])) for tup in zip(fileid_lst, all_transf_books_lst)]\n",
    "    avg_num_tokens = int(np.mean([len(book) for book in all_transf_books_lst]))\n",
    "    \n",
    "    dictionary = corpora.Dictionary(all_transf_books_lst)\n",
    "    dictionary_length = len(dictionary)\n",
    "    \n",
    "    corpus = [dictionary.doc2bow(book) for book in all_transf_books_lst]\n",
    "    \n",
    "    unique_toks_num_lst = [len(book) for book in corpus]\n",
    "    unique_toks_per_fileid = zip(fileid_lst, unique_toks_num_lst)\n",
    "    avg_unique_toks = int(np.mean(unique_toks_num_lst))\n",
    "    \n",
    "    \n",
    "    return book_lengths, avg_num_tokens, dictionary, dictionary_length, unique_toks_per_fileid, avg_unique_toks, corpus\n",
    "\n",
    "\n",
    "def save_stuff(distinguishing_str, dictionary, corpus, outputs_dir=outputs_dir):\n",
    "    '''\n",
    "    Save the outputs of the most recent eda step\n",
    "    '''\n",
    "    dictionary.save(outputs_dir + distinguishing_str + '.dict')\n",
    "    corpora.MmCorpus.serialize(outputs_dir + distinguishing_str + '_corpus.mm', corpus)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA items\n",
    "* List of book lengths (total num of tokens for each book)\n",
    "* Average number of tokens per book\n",
    "* Number of words in corpus (dictionary length)\n",
    "    * Dictionary (not viewed)\n",
    "* Unique tokens per book\n",
    "* Average number of unique tokens per book\n",
    "    * Corpus (not viewe)\n",
    "    \n",
    "Save everything after eda step\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To summarize the 'simple tokenization' EDA step (#1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_v1 = eda(transform_txt_file_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "book_lengths1, avg_num_tokens1, dictionary1, dictionary_length1, unique_toks_per_fileid1, \\\n",
    "    avg_unique_toks1, corpus1 = output_v1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of tokens in a book:  132124\n",
      "   \n",
      "Average unique tokens in a book:  9004\n",
      "   \n",
      "Total number of words (dictionary length):  195104\n"
     ]
    }
   ],
   "source": [
    "print \"Average number of tokens in a book: \", avg_num_tokens1\n",
    "print \"   \"\n",
    "print \"Average unique tokens in a book: \", avg_unique_toks1\n",
    "print \"   \"\n",
    "print \"Total number of words (dictionary length): \", dictionary_length1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##for pres, note the sparcity problem - 9000 vs. 195k == 186k empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_stuff('simple_tok', dictionary1, corpus1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA Step 2: + stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "set([u'all', u'just', u'being', u'over', u'both', u'through', u'yourselves', u'its', u'before', u'o', u'hadn', u'herself', u'll', u'had', u'should', u'to', u'only', u'won', u'under', u'ours', u'has', u'do', u'them', u'his', u'very', u'they', u'not', u'during', u'now', u'him', u'nor', u'd', u'did', u'didn', u'this', u'she', u'each', u'further', u'where', u'few', u'because', u'doing', u'some', u'hasn', u'are', u'our', u'ourselves', u'out', u'what', u'for', u'while', u're', u'does', u'above', u'between', u'mustn', u't', u'be', u'we', u'who', u'were', u'here', u'shouldn', u'hers', u'by', u'on', u'about', u'couldn', u'of', u'against', u's', u'isn', u'or', u'own', u'into', u'yourself', u'down', u'mightn', u'wasn', u'your', u'from', u'her', u'their', u'aren', u'there', u'been', u'whom', u'too', u'wouldn', u'themselves', u'weren', u'was', u'until', u'more', u'himself', u'that', u'but', u'don', u'with', u'than', u'those', u'he', u'me', u'myself', u'ma', u'these', u'up', u'will', u'below', u'ain', u'can', u'theirs', u'my', u'and', u've', u'then', u'is', u'am', u'it', u'doesn', u'an', u'as', u'itself', u'at', u'have', u'in', u'any', u'if', u'again', u'no', u'when', u'same', u'how', u'other', u'which', u'you', u'shan', u'needn', u'haven', u'after', u'most', u'such', u'why', u'a', u'off', u'i', u'm', u'yours', u'so', u'y', u'the', u'having', u'once'])\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop = set(stopwords.words('english'))\n",
    "print stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transform_txt_file_v2(fname, root=source_dir, stop_words=stop):\n",
    "    '''\n",
    "    Top-level function to call all of the subfunctions for text transformation\n",
    "    Assumes you want to remove empty lines and tokenize (because you do)\n",
    "    '''\n",
    "    fp = root + fname\n",
    "    book_as_lst = []\n",
    "    for line in IterFile(fp):\n",
    "        \n",
    "        if empty_line_check(line) == False:\n",
    "            line = basic_tokenize(line)\n",
    "            \n",
    "            if stop_words !=None:\n",
    "                line = remove_stop_words(line, stop_words)\n",
    "        \n",
    "        book_as_lst.extend(line)\n",
    "        \n",
    "    return book_as_lst\n",
    "\n",
    "def empty_line_check(line) :\n",
    "    '''\n",
    "    checks for empty line\n",
    "    '''\n",
    "    if line == \"\\n\":\n",
    "        empty = True\n",
    "    else:\n",
    "        empty = False\n",
    "    return empty\n",
    "    \n",
    "def basic_tokenize(line):\n",
    "    '''\n",
    "    convert to list\n",
    "    strip punctuation, lowercase\n",
    "    '''\n",
    "    return [tok.lower().strip(punctuation) for tok in line.strip('\\n').split()]    \n",
    "            \n",
    "def remove_stop_words(line, stop_words):\n",
    "    return [tok for tok in line if tok not in stop_words] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_v2 = eda(transform_txt_file_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "book_lengths2, avg_num_tokens2, dictionary2, dictionary_length2, \\\n",
    "    unique_toks_per_fileid2, avg_unique_toks2, corpus2 = output_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of tokens in a book:  66904\n",
      "   \n",
      "Average unique tokens in a book:  8882\n",
      "   \n",
      "Total number of words (dictionary length):  194961\n"
     ]
    }
   ],
   "source": [
    "print \"Average number of tokens in a book: \", avg_num_tokens2\n",
    "print \"   \"\n",
    "print \"Average unique tokens in a book: \", avg_unique_toks2\n",
    "print \"   \"\n",
    "print \"Total number of words (dictionary length): \", dictionary_length2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make graph of reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_stuff('no_stopwords', dictionary2, corpus2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA Step 4: + frequency filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def eda_w_filter(transform_txt_file, fileid_lst=fileid_lst):\n",
    "    '''\n",
    "    Do transformations with updated transformation function and return all the eda items\n",
    "    '''\n",
    "    \n",
    "    all_transf_books_lst = [transform_txt_file(f) for f in fileid_lst]\n",
    "    \n",
    "    book_lengths = [(tup[0], len(tup[1])) for tup in zip(fileid_lst, all_transf_books_lst)]\n",
    "    avg_num_tokens = int(np.mean([len(book) for book in all_transf_books_lst]))\n",
    "    \n",
    "    dictionary = corpora.Dictionary(all_transf_books_lst)\n",
    "    dictionary.filter_extremes(no_below=1)\n",
    "    dictionary_length = len(dictionary)\n",
    "    \n",
    "    corpus = [dictionary.doc2bow(book) for book in all_transf_books_lst]\n",
    "    \n",
    "    unique_toks_num_lst = [len(book) for book in corpus]\n",
    "    unique_toks_per_fileid = zip(fileid_lst, unique_toks_num_lst)\n",
    "    avg_unique_toks = int(np.mean(unique_toks_num_lst))\n",
    "    \n",
    "    \n",
    "    return book_lengths, avg_num_tokens, dictionary, dictionary_length, unique_toks_per_fileid, avg_unique_toks, corpus\n",
    "\n",
    "\n",
    "def save_stuff(distinguishing_str, dictionary, corpus, model, outputs_dir=outputs_dir):\n",
    "    '''\n",
    "    Save the outputs of the most recent eda step\n",
    "    '''\n",
    "    if dictionary != None:\n",
    "        dictionary.save(outputs_dir + distinguishing_str + '.dict')\n",
    "        \n",
    "    if corpus != None:\n",
    "        corpora.MmCorpus.serialize(outputs_dir + distinguishing_str + '_corpus.mm', corpus)\n",
    "    \n",
    "    if model != None:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputs4 = eda_w_filter(transform_txt_file_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "book_lengths4, avg_num_tokens4, dictionary4, dictionary_length4, \\\n",
    "    unique_toks_per_fileid4, avg_unique_toks4, corpus4 = outputs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of tokens in a book:  66904 66904\n",
      "   \n",
      "Average unique tokens in a book:  5461 8882\n",
      "   \n",
      "Total number of words (dictionary length):  100000 194961\n"
     ]
    }
   ],
   "source": [
    "print \"Average number of tokens in a book: \", avg_num_tokens4, avg_num_tokens2\n",
    "print \"   \"\n",
    "print \"Average unique tokens in a book: \", avg_unique_toks4, avg_unique_toks2\n",
    "print \"   \"\n",
    "print \"Total number of words (dictionary length): \", dictionary_length4, dictionary_length2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_stuff('frequency_filtered', dictionary4, corpus4, model=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction Summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "book_lengths4, avg_num_tokens4, dictionary4, dictionary_length4, \\\n",
    "    unique_toks_per_fileid4, avg_unique_toks4, corpus4 = outputs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average unique words per book: \n",
      "    Initial (tokenized):  132124\n",
      "    Stop words removed:  66904\n",
      "    Frequency filtered:  66904\n",
      "   \n",
      "Average unique words per book: \n",
      "    Initial (tokenized):  9004\n",
      "    Stop words removed:  8882\n",
      "    Frequency filtered:  5461\n",
      "   \n",
      "Vocabulary length: \n",
      "    Initial (tokenized):  195104\n",
      "    Stop words removed:  194961\n",
      "    Frequency filtered:  100000\n"
     ]
    }
   ],
   "source": [
    "print \"Average unique words per book: \"\n",
    "print \"   \", \"Initial (tokenized): \", avg_num_tokens1\n",
    "print \"   \", \"Stop words removed: \", avg_num_tokens2\n",
    "print \"   \", \"Frequency filtered: \", avg_num_tokens4\n",
    "print \"   \"\n",
    "print \"Average unique words per book: \"\n",
    "print \"   \", \"Initial (tokenized): \", avg_unique_toks1\n",
    "print \"   \", \"Stop words removed: \", avg_unique_toks2\n",
    "print \"   \", \"Frequency filtered: \", avg_unique_toks4\n",
    "print \"   \"\n",
    "print \"Vocabulary length: \"\n",
    "print \"   \", \"Initial (tokenized): \", dictionary_length1\n",
    "print \"   \", \"Stop words removed: \", dictionary_length2\n",
    "print \"   \", \"Frequency filtered: \", dictionary_length4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([132124, 66904, 66904], [9004, 8882, 5461], [195104, 194961, 100000])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_num_tokens_lst = [avg_num_tokens1, avg_num_tokens2, avg_num_tokens4]\n",
    "avg_unique_toks_lst =  [avg_unique_toks1, avg_unique_toks2, avg_unique_toks4]\n",
    "vocab_size_lst =[dictionary_length1, dictionary_length2, dictionary_length4]\n",
    "avg_num_tokens_lst, avg_unique_toks_lst, vocab_size_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([9004, 132124, 195104], [8882, 66904, 194961], [5461, 66904, 100000])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_lst = [avg_unique_toks1, avg_num_tokens1, dictionary_length1]\n",
    "stop_words_removed_lst =  [avg_unique_toks2, avg_num_tokens2, dictionary_length2]\n",
    "frequency_filtered_lst =[avg_unique_toks4, avg_num_tokens4, dictionary_length4]\n",
    "tokenized_lst, stop_words_removed_lst, frequency_filtered_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#%matplotinline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa3a1381710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_groups = 3\n",
    "pos = list(range(n_groups))\n",
    "\n",
    "dim_red_1 = tokenized_lst\n",
    "\n",
    "dim_red_2 = stop_words_removed_lst\n",
    "\n",
    "dim_red_3 = frequency_filtered_lst\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "pos = list(range(n_groups))\n",
    "bar_width = 0.25\n",
    "\n",
    "opacity = 0.4\n",
    "error_config = {'ecolor': '0.3'}\n",
    "\n",
    "rects1 = plt.bar(pos, \n",
    "                 dim_red_1, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 #color='b',\n",
    "                 label='Initial')\n",
    "\n",
    "rects2 = plt.bar([p + bar_width for p in pos], \n",
    "                 dim_red_2, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 #color='b',\n",
    "                 label='Stop Word Removal')\n",
    "\n",
    "rects3 = plt.bar([p + bar_width*2 for p in pos], \n",
    "                 dim_red_3, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 #color='b',\n",
    "                 label= 'Frequency Filtering')\n",
    "\n",
    "#plt.xlabel('Group')\n",
    "plt.ylabel('Number of Words')\n",
    "plt.title('Counts Over Dimensionality Reduction')\n",
    "plt.xticks(index + bar_width / 2, ('Avg unique per book', \\\n",
    "                        'Avg total per book', 'Total vocab size'))\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 27.2 Âµs\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import ldamodel\n",
    "from gensim.models import LdaMulticore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda = ldamodel.LdaModel(corpus=corpus4,alpha='auto', id2word=dictionary2, \\\n",
    "                        num_topics=100, update_every=0, passes=20)\n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name = 'lda.model'\n",
    "lda.save(outputs_dir + name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LdaModel(num_terms=194961, num_topics=10, decay=0.5, chunksize=2000)\n"
     ]
    }
   ],
   "source": [
    "print lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ae3876220e0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlda_multi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLdaMulticore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdictionary4\u001b[0m\u001b[0;34m,\u001b[0m                         \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'corpus4' is not defined"
     ]
    }
   ],
   "source": [
    "lda_multi = LdaMulticore(corpus=corpus4,alpha='auto', id2word=dictionary4, \\\n",
    "                        num_topics=100, update_every=0, passes=20, workers=4)\n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name = 'lda_multi.model'\n",
    "lda_multi.save(outputs_dir + name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LdaModel(num_terms=194961, num_topics=10, decay=0.5, chunksize=2000)\n"
     ]
    }
   ],
   "source": [
    "print lda_multi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the topics and their most significant terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.027*\"\\n\" + 0.007*\"one\" + 0.007*\"would\" + 0.005*\"may\" + 0.004*\"man\" + 0.004*\"small\" + 0.004*\"said\" + 0.004*\"upon\" + 0.004*\"letter\" + 0.003*\"us\"'),\n",
       " (1,\n",
       "  u'0.036*\"\\n\" + 0.010*\"said\" + 0.007*\"would\" + 0.007*\"one\" + 0.006*\"could\" + 0.005*\"mr\" + 0.004*\"know\" + 0.004*\"time\" + 0.004*\"little\" + 0.004*\"see\"'),\n",
       " (2,\n",
       "  u'0.038*\"\\n\" + 0.007*\"one\" + 0.006*\"said\" + 0.004*\"would\" + 0.004*\"man\" + 0.003*\"us\" + 0.003*\"time\" + 0.003*\"like\" + 0.003*\"could\" + 0.003*\"much\"'),\n",
       " (3,\n",
       "  u'0.036*\"\\n\" + 0.008*\"man\" + 0.007*\"god\" + 0.007*\"men\" + 0.007*\"ich\" + 0.006*\"power\" + 0.006*\"one\" + 0.005*\"law\" + 0.004*\"also\" + 0.004*\"therefore\"'),\n",
       " (4,\n",
       "  u'0.055*\"\\n\" + 0.022*\"shall\" + 0.020*\"unto\" + 0.017*\"lord\" + 0.013*\"thou\" + 0.011*\"thy\" + 0.010*\"god\" + 0.009*\"thee\" + 0.009*\"ye\" + 0.009*\"said\"'),\n",
       " (5,\n",
       "  u'0.056*\"\\n\" + 0.008*\"said\" + 0.007*\"one\" + 0.005*\"man\" + 0.004*\"would\" + 0.003*\"upon\" + 0.003*\"like\" + 0.003*\"two\" + 0.003*\"could\" + 0.003*\"little\"'),\n",
       " (6,\n",
       "  u'0.038*\"\\n\" + 0.019*\"said\" + 0.008*\"one\" + 0.006*\"would\" + 0.006*\"went\" + 0.006*\"got\" + 0.005*\"could\" + 0.005*\"little\" + 0.005*\"see\" + 0.005*\"go\"'),\n",
       " (7,\n",
       "  u'0.017*\"\\n\" + 0.009*\"would\" + 0.009*\"one\" + 0.007*\"could\" + 0.006*\"upon\" + 0.005*\"time\" + 0.005*\"man\" + 0.004*\"came\" + 0.004*\"made\" + 0.004*\"men\"'),\n",
       " (8,\n",
       "  u'0.011*\"things\" + 0.011*\"thou\" + 0.008*\"earth\" + 0.007*\"\\n\" + 0.005*\"doth\" + 0.005*\"either\" + 0.005*\"nature\" + 0.005*\"unto\" + 0.004*\"thyself\" + 0.004*\"globe\"'),\n",
       " (9,\n",
       "  u'0.019*\"\\n\" + 0.011*\"thou\" + 0.008*\"thy\" + 0.006*\"thee\" + 0.006*\"shall\" + 0.004*\"good\" + 0.004*\"king\" + 0.004*\"lord\" + 0.004*\"one\" + 0.004*\"come\"')]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.show_topics()\n",
    "#also lda.show_topics() - what is difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given document (in bow format), see most relevant topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.83551263725276792),\n",
       " (1, 0.017758247818321121),\n",
       " (4, 0.033966879261823679),\n",
       " (7, 0.11079299655988328)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.get_document_topics(dictionary2.doc2bow(transform_txt_file_v2('1080-clean.txt')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given term in vocab, see what topics are most likely/relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.00081795748432229377),\n",
       " (1, 0.00046665540461913628),\n",
       " (2, 0.00039821109443075416),\n",
       " (3, 0.00089142134354498184),\n",
       " (4, 0.00070689873255245941),\n",
       " (5, 0.00075794148467451953),\n",
       " (6, 0.00025252416712527251),\n",
       " (7, 0.00044098219041034128),\n",
       " (8, 0.00014582208768044617),\n",
       " (9, 0.0016219715531712738)]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.get_term_topics(100, minimum_probability=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverse of above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10364, 0.035504333182389526),\n",
       " (8954, 0.0096323354543700022),\n",
       " (12919, 0.0073228099915345771),\n",
       " (1443, 0.006681396288898224),\n",
       " (3530, 0.0063353405287126258),\n",
       " (39835, 0.0052772699844260773),\n",
       " (16982, 0.0042263928343234903),\n",
       " (1031, 0.0036816693497437052),\n",
       " (9837, 0.00359973572788477),\n",
       " (2690, 0.0035094699408091535)]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.get_topic_terms(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "one\n",
      "would\n",
      "may\n",
      "man\n",
      "small\n",
      "said\n",
      "upon\n",
      "letter\n",
      "us\n"
     ]
    }
   ],
   "source": [
    "for tup in lda.get_topic_terms(0):\n",
    "    print dictionary2[tup[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Document alignment\n",
    "#softmax - zeroing - zero out all not in the top2 alignment\n",
    "    #manually creat label from top word\n",
    "    #need to include logic to use two topics if below certain threshhold\n",
    "#projection - \n",
    "#cos sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python2]",
   "language": "python",
   "name": "conda-env-python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
