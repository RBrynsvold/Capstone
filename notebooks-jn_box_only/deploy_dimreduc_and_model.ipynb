{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, codecs\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from collections import defaultdict\n",
    "import string\n",
    "from string import punctuation\n",
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THESE SHOULD BE ALL THE RELATIVE PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_dir = '/Users/rachelbrynsvold/dsi/capstone_dir/Capstone/books/clean' + '/'\n",
    "outputs_dir = '/Users/rachelbrynsvold/dsi/capstone_dir/Capstone/outputs' + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class IterFile(object):\n",
    "    '''\n",
    "    class object to do the iterating on individual book txt documents, including file i/o.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = filepath\n",
    "        \n",
    "    def _open_file(self):\n",
    "        self.file = codecs.open(self.filepath, 'r', encoding='utf_8')\n",
    "        \n",
    "    def _close_file(self):\n",
    "        self.file.close()\n",
    "    \n",
    "    def __iter__(self):\n",
    "        '''\n",
    "        overwrite iteration to include file i/o\n",
    "        '''\n",
    "        self._open_file()\n",
    "        \n",
    "        for line in self.file:\n",
    "            yield line\n",
    "        \n",
    "        self._close_file()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_txt_file_v1(fname, root=source_dir):\n",
    "    '''\n",
    "    Initial pass at text transformation\n",
    "    Reimplemented later (v2 etc) as a caller of various subfunctions to do all the transformation\n",
    "    '''\n",
    "    fp = root + fname\n",
    "\n",
    "    book_as_lst = []\n",
    "    for line in IterFile(fp):\n",
    "        if line == \"\\n\":\n",
    "            pass\n",
    "        else: \n",
    "            line_lst= [tok.lower().strip(punctuation) for tok in line.strip('\\n').split()]\n",
    "            book_as_lst.extend(line_lst)\n",
    "            \n",
    "    #add in stop word removal and frequency threshhold\n",
    "    return book_as_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10-clean.txt',\n",
       " '100-clean.txt',\n",
       " '105-clean.txt',\n",
       " '108-clean.txt',\n",
       " '1080-clean.txt',\n",
       " '11-clean.txt',\n",
       " '1112-clean.txt',\n",
       " '1184-clean.txt',\n",
       " '12-clean.txt',\n",
       " '120-clean.txt',\n",
       " '1232-clean.txt',\n",
       " '1260-clean.txt',\n",
       " '1322-clean.txt',\n",
       " '1342-clean.txt',\n",
       " '135-clean.txt',\n",
       " '1399-clean.txt',\n",
       " '140-clean.txt',\n",
       " '1400-clean.txt',\n",
       " '1404-clean.txt',\n",
       " '14264-clean.txt',\n",
       " '147-clean.txt',\n",
       " '1497-clean.txt',\n",
       " '15399-clean.txt',\n",
       " '158-clean.txt',\n",
       " '16-clean.txt',\n",
       " '160-clean.txt',\n",
       " '161-clean.txt',\n",
       " '16382-clean.txt',\n",
       " '1661-clean.txt',\n",
       " '1727-clean.txt',\n",
       " '174-clean.txt',\n",
       " '1952-yellow_wallpaper-clean.txt',\n",
       " '19942-clean.txt',\n",
       " '20-clean.txt',\n",
       " '20203-clean.txt',\n",
       " '203-clean.txt',\n",
       " '205-clean.txt',\n",
       " '21279-clean.txt',\n",
       " '2148-clean.txt',\n",
       " '2174-clean.txt',\n",
       " '219-clean.txt',\n",
       " '224-clean.txt',\n",
       " '23-clean.txt',\n",
       " '236-clean.txt',\n",
       " '2500-clean.txt',\n",
       " '25305-clean.txt',\n",
       " '2591-clean.txt',\n",
       " '2600-clean.txt',\n",
       " '2680-clean.txt',\n",
       " '2701-moby-clean.txt',\n",
       " '28054-clean.txt',\n",
       " '2814-clean.txt',\n",
       " '2852-clean.txt',\n",
       " '28520-clean.txt',\n",
       " '30360-clean.txt',\n",
       " '30601-clean.txt',\n",
       " '3207-clean.txt',\n",
       " '33-clean.txt',\n",
       " '33283-clean.txt',\n",
       " '345-clean.txt',\n",
       " '34901-clean.txt',\n",
       " '35-clean.txt',\n",
       " '36-clean.txt',\n",
       " '3600-clean.txt',\n",
       " '38427-clean.txt',\n",
       " '408-clean.txt',\n",
       " '41-clean.txt',\n",
       " '42-clean.txt',\n",
       " '4300-clean.txt',\n",
       " '4363-clean.txt',\n",
       " '45-clean.txt',\n",
       " '4517-clean.txt',\n",
       " '46-clean.txt',\n",
       " '514-clean.txt',\n",
       " '5200-clean.txt',\n",
       " '521-clean.txt',\n",
       " '526-clean.txt',\n",
       " '55-clean.txt',\n",
       " '55387-clean.txt',\n",
       " '55404-clean.txt',\n",
       " '6130-clean.txt',\n",
       " '730-clean.txt',\n",
       " '7370-clean.txt',\n",
       " '74-clean.txt',\n",
       " '76-clean.txt',\n",
       " '768-clean.txt',\n",
       " '829-clean.txt',\n",
       " '84-clean.txt',\n",
       " '844-clean.txt',\n",
       " '851-clean.txt',\n",
       " '863-clean.txt',\n",
       " '8800-clean.txt',\n",
       " '932-clean.txt',\n",
       " '98-clean.txt',\n",
       " '996-clean.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_corp = PlaintextCorpusReader(source_dir, '.*\\.txt')\n",
    "fileid_lst = temp_corp.fileids()\n",
    "fileid_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA and Saving helper funtions\n",
    "\n",
    "To automate EDA steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def eda(transform_txt_file, fileid_lst=fileid_lst):\n",
    "    '''\n",
    "    Do transformations with updated transformation function and return all the eda items\n",
    "    '''\n",
    "    \n",
    "    all_transf_books_lst = [transform_txt_file(f) for f in fileid_lst]\n",
    "    \n",
    "    book_lengths = [(tup[0], len(tup[1])) for tup in zip(fileid_lst, all_transf_books_lst)]\n",
    "    avg_num_tokens = int(np.mean([len(book) for book in all_transf_books_lst]))\n",
    "    \n",
    "    dictionary = corpora.Dictionary(all_transf_books_lst)\n",
    "    dictionary_length = len(dictionary)\n",
    "    \n",
    "    corpus = [dictionary.doc2bow(book) for book in all_transf_books_lst]\n",
    "    \n",
    "    unique_toks_num_lst = [len(book) for book in corpus]\n",
    "    unique_toks_per_fileid = zip(fileid_lst, unique_toks_num_lst)\n",
    "    avg_unique_toks = int(np.mean(unique_toks_num_lst))\n",
    "    \n",
    "    \n",
    "    return book_lengths, avg_num_tokens, dictionary, dictionary_length, unique_toks_per_fileid, avg_unique_toks, corpus\n",
    "\n",
    "\n",
    "def save_stuff(distinguishing_str, dictionary, corpus, outputs_dir=outputs_dir):\n",
    "    '''\n",
    "    Save the outputs of the most recent eda step\n",
    "    '''\n",
    "    dictionary.save(outputs_dir + distinguishing_str + '.dict')\n",
    "    corpora.MmCorpus.serialize(outputs_dir + distinguishing_str + '_corpus.mm', corpus)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA items\n",
    "* List of book lengths (total num of tokens for each book)\n",
    "* Average number of tokens per book\n",
    "* Number of words in corpus (dictionary length)\n",
    "    * Dictionary (not viewed)\n",
    "* Unique tokens per book\n",
    "* Average number of unique tokens per book\n",
    "    * Corpus (not viewe)\n",
    "    \n",
    "Save everything after eda step\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To summarize the 'simple tokenization' EDA step (#1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_v1 = eda(transform_txt_file_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "book_lengths1, avg_num_tokens1, dictionary1, dictionary_length1, unique_toks_per_fileid1, \\\n",
    "    avg_unique_toks1, corpus1 = output_v1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of tokens in a book:  132124\n",
      "   \n",
      "Average unique tokens in a book:  9004\n",
      "   \n",
      "Total number of words (dictionary length):  195104\n"
     ]
    }
   ],
   "source": [
    "print \"Average number of tokens in a book: \", avg_num_tokens1\n",
    "print \"   \"\n",
    "print \"Average unique tokens in a book: \", avg_unique_toks1\n",
    "print \"   \"\n",
    "print \"Total number of words (dictionary length): \", dictionary_length1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##for pres, note the sparcity problem - 9000 vs. 195k == 186k empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_stuff('simple_tok', dictionary1, corpus1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA Step 2: + stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rachelbrynsvold/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "set([u'all', u'just', u'being', u'over', u'both', u'through', u'yourselves', u'its', u'before', u'o', u'hadn', u'herself', u'll', u'had', u'should', u'to', u'only', u'won', u'under', u'ours', u'has', u'do', u'them', u'his', u'very', u'they', u'not', u'during', u'now', u'him', u'nor', u'd', u'did', u'didn', u'this', u'she', u'each', u'further', u'where', u'few', u'because', u'doing', u'some', u'hasn', u'are', u'our', u'ourselves', u'out', u'what', u'for', u'while', u're', u'does', u'above', u'between', u'mustn', u't', u'be', u'we', u'who', u'were', u'here', u'shouldn', u'hers', u'by', u'on', u'about', u'couldn', u'of', u'against', u's', u'isn', u'or', u'own', u'into', u'yourself', u'down', u'mightn', u'wasn', u'your', u'from', u'her', u'their', u'aren', u'there', u'been', u'whom', u'too', u'wouldn', u'themselves', u'weren', u'was', u'until', u'more', u'himself', u'that', u'but', u'don', u'with', u'than', u'those', u'he', u'me', u'myself', u'ma', u'these', u'up', u'will', u'below', u'ain', u'can', u'theirs', u'my', u'and', u've', u'then', u'is', u'am', u'it', u'doesn', u'an', u'as', u'itself', u'at', u'have', u'in', u'any', u'if', u'again', u'no', u'when', u'same', u'how', u'other', u'which', u'you', u'shan', u'needn', u'haven', u'after', u'most', u'such', u'why', u'a', u'off', u'i', u'm', u'yours', u'so', u'y', u'the', u'having', u'once'])\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop = set(stopwords.words('english'))\n",
    "print stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_txt_file_v2(fname, root=source_dir, stop_words=stop):\n",
    "    '''\n",
    "    Top-level function to call all of the subfunctions for text transformation\n",
    "    Assumes you want to remove empty lines and tokenize (because you do)\n",
    "    '''\n",
    "    fp = root + fname\n",
    "    book_as_lst = []\n",
    "    for line in IterFile(fp):\n",
    "        \n",
    "        if empty_line_check(line) == False:\n",
    "            line = basic_tokenize(line)\n",
    "            \n",
    "            if stop_words !=None:\n",
    "                line = remove_stop_words(line, stop_words)\n",
    "        \n",
    "            book_as_lst.extend(line)\n",
    "        \n",
    "    return book_as_lst\n",
    "\n",
    "def empty_line_check(line) :\n",
    "    '''\n",
    "    checks for empty line\n",
    "    '''\n",
    "    if line == \"\\n\":\n",
    "        empty = True\n",
    "    else:\n",
    "        empty = False\n",
    "    return empty\n",
    "    \n",
    "def basic_tokenize(line):\n",
    "    '''\n",
    "    convert to list\n",
    "    strip punctuation, lowercase\n",
    "    '''\n",
    "    return [tok.lower().strip(punctuation) for tok in line.strip('\\n').split()]    \n",
    "            \n",
    "def remove_stop_words(line, stop_words):\n",
    "    return [tok for tok in line if tok not in stop_words] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_v2 = eda(transform_txt_file_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "book_lengths2, avg_num_tokens2, dictionary2, dictionary_length2, \\\n",
    "    unique_toks_per_fileid2, avg_unique_toks2, corpus2 = output_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of tokens in a book:  66904\n",
      "   \n",
      "Average unique tokens in a book:  8882\n",
      "   \n",
      "Total number of words (dictionary length):  194961\n"
     ]
    }
   ],
   "source": [
    "print \"Average number of tokens in a book: \", avg_num_tokens2\n",
    "print \"   \"\n",
    "print \"Average unique tokens in a book: \", avg_unique_toks2\n",
    "print \"   \"\n",
    "print \"Total number of words (dictionary length): \", dictionary_length2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make graph of reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_stuff('no_stopwords', dictionary2, corpus2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA Step 4: + frequency filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def eda_w_filter(transform_txt_file, fileid_lst=fileid_lst):\n",
    "    '''\n",
    "    Do transformations with updated transformation function and return all the eda items\n",
    "    '''\n",
    "    \n",
    "    all_transf_books_lst = [transform_txt_file(f) for f in fileid_lst]\n",
    "    \n",
    "    book_lengths = [(tup[0], len(tup[1])) for tup in zip(fileid_lst, all_transf_books_lst)]\n",
    "    avg_num_tokens = int(np.mean([len(book) for book in all_transf_books_lst]))\n",
    "    \n",
    "    dictionary = corpora.Dictionary(all_transf_books_lst)\n",
    "    dictionary.filter_extremes(no_below=1)\n",
    "    dictionary_length = len(dictionary)\n",
    "    \n",
    "    corpus = [dictionary.doc2bow(book) for book in all_transf_books_lst]\n",
    "    \n",
    "    unique_toks_num_lst = [len(book) for book in corpus]\n",
    "    unique_toks_per_fileid = zip(fileid_lst, unique_toks_num_lst)\n",
    "    avg_unique_toks = int(np.mean(unique_toks_num_lst))\n",
    "    \n",
    "    \n",
    "    return book_lengths, avg_num_tokens, dictionary, dictionary_length, unique_toks_per_fileid, avg_unique_toks, corpus\n",
    "\n",
    "\n",
    "def save_stuff(distinguishing_str, dictionary, corpus, model, outputs_dir=outputs_dir):\n",
    "    '''\n",
    "    Save the outputs of the most recent eda step\n",
    "    '''\n",
    "    if dictionary != None:\n",
    "        dictionary.save(outputs_dir + distinguishing_str + '.dict')\n",
    "        \n",
    "    if corpus != None:\n",
    "        corpora.MmCorpus.serialize(outputs_dir + distinguishing_str + '_corpus.mm', corpus)\n",
    "    \n",
    "    if model != None:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs4 = eda_w_filter(transform_txt_file_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "book_lengths4, avg_num_tokens4, dictionary4, dictionary_length4, \\\n",
    "    unique_toks_per_fileid4, avg_unique_toks4, corpus4 = outputs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of tokens in a book:  66904 66904\n",
      "   \n",
      "Average unique tokens in a book:  5461 8882\n",
      "   \n",
      "Total number of words (dictionary length):  100000 194961\n"
     ]
    }
   ],
   "source": [
    "print \"Average number of tokens in a book: \", avg_num_tokens4, avg_num_tokens2\n",
    "print \"   \"\n",
    "print \"Average unique tokens in a book: \", avg_unique_toks4, avg_unique_toks2\n",
    "print \"   \"\n",
    "print \"Total number of words (dictionary length): \", dictionary_length4, dictionary_length2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_stuff('frequency_filtered', dictionary4, corpus4, model=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction Summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "book_lengths4, avg_num_tokens4, dictionary4, dictionary_length4, \\\n",
    "    unique_toks_per_fileid4, avg_unique_toks4, corpus4 = outputs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average total words per book: \n",
      "    Initial (tokenized):  132124\n",
      "    Stop words removed:  66904\n",
      "    Frequency filtered:  66904\n",
      "   \n",
      "Average unique words per book: \n",
      "    Initial (tokenized):  9004\n",
      "    Stop words removed:  8882\n",
      "    Frequency filtered:  5461\n",
      "   \n",
      "Vocabulary length: \n",
      "    Initial (tokenized):  195104\n",
      "    Stop words removed:  194961\n",
      "    Frequency filtered:  100000\n"
     ]
    }
   ],
   "source": [
    "print \"Average total words per book: \"\n",
    "print \"   \", \"Initial (tokenized): \", avg_num_tokens1\n",
    "print \"   \", \"Stop words removed: \", avg_num_tokens2\n",
    "print \"   \", \"Frequency filtered: \", avg_num_tokens4\n",
    "print \"   \"\n",
    "print \"Average unique words per book: \"\n",
    "print \"   \", \"Initial (tokenized): \", avg_unique_toks1\n",
    "print \"   \", \"Stop words removed: \", avg_unique_toks2\n",
    "print \"   \", \"Frequency filtered: \", avg_unique_toks4\n",
    "print \"   \"\n",
    "print \"Vocabulary length: \"\n",
    "print \"   \", \"Initial (tokenized): \", dictionary_length1\n",
    "print \"   \", \"Stop words removed: \", dictionary_length2\n",
    "print \"   \", \"Frequency filtered: \", dictionary_length4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([132124, 66904, 66904], [9004, 8882, 5461], [195104, 194961, 100000])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_num_tokens_lst = [avg_num_tokens1, avg_num_tokens2, avg_num_tokens4]\n",
    "avg_unique_toks_lst =  [avg_unique_toks1, avg_unique_toks2, avg_unique_toks4]\n",
    "vocab_size_lst =[dictionary_length1, dictionary_length2, dictionary_length4]\n",
    "avg_num_tokens_lst, avg_unique_toks_lst, vocab_size_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([9004, 132124, 195104], [8882, 66904, 194961], [5461, 66904, 100000])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_lst = [avg_unique_toks1, avg_num_tokens1, dictionary_length1]\n",
    "stop_words_removed_lst =  [avg_unique_toks2, avg_num_tokens2, dictionary_length2]\n",
    "frequency_filtered_lst =[avg_unique_toks4, avg_num_tokens4, dictionary_length4]\n",
    "tokenized_lst, stop_words_removed_lst, frequency_filtered_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#%matplotinline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-49777c82f6c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of Words'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Counts Over Dimensionality Reduction'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbar_width\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Avg unique per book'\u001b[0m\u001b[0;34m,\u001b[0m                         \u001b[0;34m'Avg total per book'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Total vocab size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'index' is not defined"
     ]
    }
   ],
   "source": [
    "n_groups = 3\n",
    "pos = list(range(n_groups))\n",
    "\n",
    "dim_red_1 = tokenized_lst\n",
    "\n",
    "dim_red_2 = stop_words_removed_lst\n",
    "\n",
    "dim_red_3 = frequency_filtered_lst\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "pos = list(range(n_groups))\n",
    "bar_width = 0.25\n",
    "\n",
    "opacity = 0.4\n",
    "error_config = {'ecolor': '0.3'}\n",
    "\n",
    "rects1 = plt.bar(pos, \n",
    "                 dim_red_1, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 #color='b',\n",
    "                 label='Initial')\n",
    "\n",
    "rects2 = plt.bar([p + bar_width for p in pos], \n",
    "                 dim_red_2, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 #color='b',\n",
    "                 label='Stop Word Removal')\n",
    "\n",
    "rects3 = plt.bar([p + bar_width*2 for p in pos], \n",
    "                 dim_red_3, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 #color='b',\n",
    "                 label= 'Frequency Filtering')\n",
    "\n",
    "#plt.xlabel('Group')\n",
    "plt.ylabel('Number of Words')\n",
    "plt.title('Counts Over Dimensionality Reduction')\n",
    "plt.xticks(index + bar_width / 2, ('Avg unique per book', \\\n",
    "                        'Avg total per book', 'Total vocab size'))\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'\\n',\n",
       " u'\\n',\n",
       " u'\\n',\n",
       " u'\\n',\n",
       " u'\\n',\n",
       " u'\\n',\n",
       " u'\\n',\n",
       " u'\\n',\n",
       " u'\\n',\n",
       " u'\\n',\n",
       " u'\\n',\n",
       " u'\\n',\n",
       " u'\\n',\n",
       " u'\\n',\n",
       " u'old',\n",
       " u'testament',\n",
       " u'king',\n",
       " u'james',\n",
       " u'version',\n",
       " u'bible',\n",
       " u'\\n',\n",
       " u'\\n',\n",
       " u'\\n',\n",
       " u'\\n',\n",
       " u'first',\n",
       " u'book',\n",
       " u'moses',\n",
       " u'called',\n",
       " u'genesis',\n",
       " u'\\n',\n",
       " u'\\n',\n",
       " u'1:1',\n",
       " u'beginning',\n",
       " u'god',\n",
       " u'created',\n",
       " u'heavens',\n",
       " u'earth',\n",
       " u'\\n',\n",
       " u'1:2',\n",
       " u'earth',\n",
       " u'without',\n",
       " u'form',\n",
       " u'void',\n",
       " u'darkness',\n",
       " u'upon',\n",
       " u'face',\n",
       " u'deep',\n",
       " u'spirit',\n",
       " u'god',\n",
       " u'moved',\n",
       " u'upon',\n",
       " u'face',\n",
       " u'waters',\n",
       " u'\\n',\n",
       " u'1:3',\n",
       " u'god',\n",
       " u'said',\n",
       " u'let',\n",
       " u'light',\n",
       " u'light',\n",
       " u'\\n',\n",
       " u'1:4',\n",
       " u'god',\n",
       " u'saw',\n",
       " u'light',\n",
       " u'good',\n",
       " u'god',\n",
       " u'divided',\n",
       " u'light',\n",
       " u'darkness',\n",
       " u'\\n',\n",
       " u'1:5',\n",
       " u'god',\n",
       " u'called',\n",
       " u'light',\n",
       " u'day',\n",
       " u'darkness',\n",
       " u'called',\n",
       " u'night',\n",
       " u'evening',\n",
       " u'morning',\n",
       " u'first',\n",
       " u'day',\n",
       " u'\\n',\n",
       " u'1:6',\n",
       " u'god',\n",
       " u'said',\n",
       " u'let',\n",
       " u'firmament',\n",
       " u'midst',\n",
       " u'waters',\n",
       " u'let',\n",
       " u'divide',\n",
       " u'waters',\n",
       " u'waters',\n",
       " u'\\n',\n",
       " u'1:7',\n",
       " u'god',\n",
       " u'made',\n",
       " u'firmament',\n",
       " u'divided',\n",
       " u'waters',\n",
       " u'firmament',\n",
       " u'waters',\n",
       " u'firmament',\n",
       " u'\\n',\n",
       " u'1:8',\n",
       " u'god',\n",
       " u'called',\n",
       " u'firmament',\n",
       " u'heaven',\n",
       " u'evening',\n",
       " u'morning',\n",
       " u'second',\n",
       " u'day',\n",
       " u'\\n',\n",
       " u'1:9',\n",
       " u'god',\n",
       " u'said',\n",
       " u'let',\n",
       " u'waters',\n",
       " u'heaven',\n",
       " u'gathered',\n",
       " u'together',\n",
       " u'unto',\n",
       " u'one',\n",
       " u'place',\n",
       " u'let',\n",
       " u'dry',\n",
       " u'land',\n",
       " u'appear',\n",
       " u'\\n',\n",
       " u'1:10',\n",
       " u'god',\n",
       " u'called',\n",
       " u'dry',\n",
       " u'land',\n",
       " u'earth',\n",
       " u'gathering',\n",
       " u'together',\n",
       " u'waters',\n",
       " u'called',\n",
       " u'seas',\n",
       " u'god',\n",
       " u'saw',\n",
       " u'good',\n",
       " u'\\n',\n",
       " u'1:11',\n",
       " u'god',\n",
       " u'said',\n",
       " u'let',\n",
       " u'earth',\n",
       " u'bring',\n",
       " u'forth',\n",
       " u'grass',\n",
       " u'herb',\n",
       " u'yielding',\n",
       " u'seed',\n",
       " u'fruit',\n",
       " u'tree',\n",
       " u'yielding',\n",
       " u'fruit',\n",
       " u'kind',\n",
       " u'whose',\n",
       " u'seed',\n",
       " u'upon',\n",
       " u'earth',\n",
       " u'\\n',\n",
       " u'1:12',\n",
       " u'earth',\n",
       " u'brought',\n",
       " u'forth',\n",
       " u'grass',\n",
       " u'herb',\n",
       " u'yielding',\n",
       " u'seed',\n",
       " u'kind',\n",
       " u'tree',\n",
       " u'yielding',\n",
       " u'fruit',\n",
       " u'whose',\n",
       " u'seed',\n",
       " u'kind',\n",
       " u'god',\n",
       " u'saw',\n",
       " u'good',\n",
       " u'\\n',\n",
       " u'1:13',\n",
       " u'evening',\n",
       " u'morning',\n",
       " u'third',\n",
       " u'day',\n",
       " u'\\n',\n",
       " u'1:14',\n",
       " u'god',\n",
       " u'said',\n",
       " u'let',\n",
       " u'lights',\n",
       " u'firmament',\n",
       " u'heaven',\n",
       " u'divide',\n",
       " u'day',\n",
       " u'night',\n",
       " u'let',\n",
       " u'signs',\n",
       " u'seasons',\n",
       " u'days',\n",
       " u'years',\n",
       " u'1:15',\n",
       " u'let',\n",
       " u'lights',\n",
       " u'firmament',\n",
       " u'heaven',\n",
       " u'give',\n",
       " u'light',\n",
       " u'upon',\n",
       " u'earth',\n",
       " u'\\n',\n",
       " u'1:16',\n",
       " u'god',\n",
       " u'made',\n",
       " u'two',\n",
       " u'great',\n",
       " u'lights',\n",
       " u'greater',\n",
       " u'light',\n",
       " u'rule',\n",
       " u'day',\n",
       " u'lesser',\n",
       " u'light',\n",
       " u'rule',\n",
       " u'night',\n",
       " u'made',\n",
       " u'stars',\n",
       " u'also',\n",
       " u'\\n',\n",
       " u'1:17',\n",
       " u'god',\n",
       " u'set',\n",
       " u'firmament',\n",
       " u'heaven',\n",
       " u'give',\n",
       " u'light',\n",
       " u'upon',\n",
       " u'earth',\n",
       " u'1:18',\n",
       " u'rule',\n",
       " u'day',\n",
       " u'night',\n",
       " u'divide',\n",
       " u'light',\n",
       " u'darkness',\n",
       " u'god',\n",
       " u'saw',\n",
       " u'good',\n",
       " u'\\n',\n",
       " u'1:19',\n",
       " u'evening',\n",
       " u'morning',\n",
       " u'fourth',\n",
       " u'day',\n",
       " u'\\n',\n",
       " u'1:20',\n",
       " u'god',\n",
       " u'said',\n",
       " u'let',\n",
       " u'waters',\n",
       " u'bring',\n",
       " u'forth',\n",
       " u'abundantly',\n",
       " u'moving',\n",
       " u'creature',\n",
       " u'hath',\n",
       " u'life',\n",
       " u'fowl',\n",
       " u'may',\n",
       " u'fly',\n",
       " u'earth',\n",
       " u'open',\n",
       " u'firmament',\n",
       " u'heaven',\n",
       " u'\\n',\n",
       " u'1:21',\n",
       " u'god',\n",
       " u'created',\n",
       " u'great',\n",
       " u'whales',\n",
       " u'every',\n",
       " u'living',\n",
       " u'creature',\n",
       " u'moveth',\n",
       " u'waters',\n",
       " u'brought',\n",
       " u'forth',\n",
       " u'abundantly',\n",
       " u'kind',\n",
       " u'every',\n",
       " u'winged',\n",
       " u'fowl',\n",
       " u'kind',\n",
       " u'god',\n",
       " u'saw',\n",
       " u'good',\n",
       " u'\\n',\n",
       " u'1:22',\n",
       " u'god',\n",
       " u'blessed',\n",
       " u'saying',\n",
       " u'fruitful',\n",
       " u'multiply',\n",
       " u'fill',\n",
       " u'waters',\n",
       " u'seas',\n",
       " u'let',\n",
       " u'fowl',\n",
       " u'multiply',\n",
       " u'earth',\n",
       " u'\\n',\n",
       " u'1:23',\n",
       " u'evening',\n",
       " u'morning',\n",
       " u'fifth',\n",
       " u'day',\n",
       " u'\\n',\n",
       " u'1:24',\n",
       " u'god',\n",
       " u'said',\n",
       " u'let',\n",
       " u'earth',\n",
       " u'bring',\n",
       " u'forth',\n",
       " u'living',\n",
       " u'creature',\n",
       " u'kind',\n",
       " u'cattle',\n",
       " u'creeping',\n",
       " u'thing',\n",
       " u'beast',\n",
       " u'earth',\n",
       " u'kind',\n",
       " u'\\n',\n",
       " u'1:25',\n",
       " u'god',\n",
       " u'made',\n",
       " u'beast',\n",
       " u'earth',\n",
       " u'kind',\n",
       " u'cattle',\n",
       " u'kind',\n",
       " u'every',\n",
       " u'thing',\n",
       " u'creepeth',\n",
       " u'upon',\n",
       " u'earth',\n",
       " u'kind',\n",
       " u'god',\n",
       " u'saw',\n",
       " u'good',\n",
       " u'\\n',\n",
       " u'1:26',\n",
       " u'god',\n",
       " u'said',\n",
       " u'let',\n",
       " u'us',\n",
       " u'make',\n",
       " u'man',\n",
       " u'image',\n",
       " u'likeness',\n",
       " u'let',\n",
       " u'dominion',\n",
       " u'fish',\n",
       " u'sea',\n",
       " u'fowl',\n",
       " u'air',\n",
       " u'cattle',\n",
       " u'earth',\n",
       " u'every',\n",
       " u'creeping',\n",
       " u'thing',\n",
       " u'creepeth',\n",
       " u'upon',\n",
       " u'earth',\n",
       " u'\\n',\n",
       " u'1:27',\n",
       " u'god',\n",
       " u'created',\n",
       " u'man',\n",
       " u'image',\n",
       " u'image',\n",
       " u'god',\n",
       " u'created',\n",
       " u'male',\n",
       " u'female',\n",
       " u'created',\n",
       " u'\\n',\n",
       " u'1:28',\n",
       " u'god',\n",
       " u'blessed',\n",
       " u'god',\n",
       " u'said',\n",
       " u'unto',\n",
       " u'fruitful',\n",
       " u'multiply',\n",
       " u'replenish',\n",
       " u'earth',\n",
       " u'subdue',\n",
       " u'dominion',\n",
       " u'fish',\n",
       " u'sea',\n",
       " u'fowl',\n",
       " u'air',\n",
       " u'every',\n",
       " u'living',\n",
       " u'thing',\n",
       " u'moveth',\n",
       " u'upon',\n",
       " u'earth',\n",
       " u'\\n',\n",
       " u'1:29',\n",
       " u'god',\n",
       " u'said',\n",
       " u'behold',\n",
       " u'given',\n",
       " u'every',\n",
       " u'herb',\n",
       " u'bearing',\n",
       " u'seed',\n",
       " u'upon',\n",
       " u'face',\n",
       " u'earth',\n",
       " u'every',\n",
       " u'tree',\n",
       " u'fruit',\n",
       " u'tree',\n",
       " u'yielding',\n",
       " u'seed',\n",
       " u'shall',\n",
       " u'meat',\n",
       " u'\\n',\n",
       " u'1:30',\n",
       " u'every',\n",
       " u'beast',\n",
       " u'earth',\n",
       " u'every',\n",
       " u'fowl',\n",
       " u'air',\n",
       " u'every',\n",
       " u'thing',\n",
       " u'creepeth',\n",
       " u'upon',\n",
       " u'earth',\n",
       " u'wherein',\n",
       " u'life',\n",
       " u'given',\n",
       " u'every',\n",
       " u'green',\n",
       " u'herb',\n",
       " u'meat',\n",
       " u'\\n',\n",
       " u'1:31',\n",
       " u'god',\n",
       " u'saw',\n",
       " u'every',\n",
       " u'thing',\n",
       " u'made',\n",
       " u'behold',\n",
       " u'good',\n",
       " u'evening',\n",
       " u'morning',\n",
       " u'sixth',\n",
       " u'day',\n",
       " u'\\n',\n",
       " u'2:1',\n",
       " u'thus',\n",
       " u'heavens',\n",
       " u'earth',\n",
       " u'finished',\n",
       " u'host',\n",
       " u'\\n',\n",
       " u'2:2',\n",
       " u'seventh',\n",
       " u'day',\n",
       " u'god',\n",
       " u'ended',\n",
       " u'work',\n",
       " u'made',\n",
       " u'rested',\n",
       " u'seventh',\n",
       " u'day',\n",
       " u'work',\n",
       " u'made',\n",
       " u'\\n',\n",
       " u'2:3',\n",
       " u'god',\n",
       " u'blessed',\n",
       " u'seventh',\n",
       " u'day',\n",
       " u'sanctified',\n",
       " u'rested',\n",
       " u'work',\n",
       " u'god',\n",
       " u'created',\n",
       " u'made',\n",
       " u'\\n',\n",
       " u'2:4',\n",
       " u'generations',\n",
       " u'heavens',\n",
       " u'earth',\n",
       " u'created',\n",
       " u'day',\n",
       " u'lord',\n",
       " u'god',\n",
       " u'made',\n",
       " u'earth',\n",
       " u'heavens',\n",
       " u'2:5',\n",
       " u'every',\n",
       " u'plant',\n",
       " u'field',\n",
       " u'earth',\n",
       " u'every',\n",
       " u'herb',\n",
       " u'field',\n",
       " u'grew',\n",
       " u'lord',\n",
       " u'god',\n",
       " u'caused',\n",
       " u'rain',\n",
       " u'upon',\n",
       " u'earth',\n",
       " u'man',\n",
       " u'till',\n",
       " u'ground',\n",
       " u'\\n',\n",
       " u'2:6',\n",
       " u'went',\n",
       " u'mist',\n",
       " u'earth',\n",
       " u'watered',\n",
       " u'whole',\n",
       " u'face',\n",
       " u'ground',\n",
       " u'\\n',\n",
       " u'2:7',\n",
       " u'lord',\n",
       " u'god',\n",
       " u'formed',\n",
       " u'man',\n",
       " u'dust',\n",
       " u'ground',\n",
       " u'breathed',\n",
       " u'nostrils',\n",
       " u'breath',\n",
       " u'life',\n",
       " u'man',\n",
       " u'became',\n",
       " u'living',\n",
       " u'soul',\n",
       " u'\\n',\n",
       " u'2:8',\n",
       " u'lord',\n",
       " u'god',\n",
       " u'planted',\n",
       " u'garden',\n",
       " u'eastward',\n",
       " u'eden',\n",
       " u'put',\n",
       " u'man',\n",
       " u'formed',\n",
       " u'\\n',\n",
       " u'2:9',\n",
       " u'ground',\n",
       " u'made',\n",
       " u'lord',\n",
       " u'god',\n",
       " u'grow',\n",
       " u'every',\n",
       " u'tree',\n",
       " u'pleasant',\n",
       " u'sight',\n",
       " u'good',\n",
       " u'food',\n",
       " u'tree',\n",
       " u'life',\n",
       " u'also',\n",
       " u'midst',\n",
       " u'garden',\n",
       " u'tree',\n",
       " u'knowledge',\n",
       " u'good',\n",
       " u'evil',\n",
       " u'\\n',\n",
       " u'2:10',\n",
       " u'river',\n",
       " u'went',\n",
       " u'eden',\n",
       " u'water',\n",
       " u'garden',\n",
       " u'thence',\n",
       " u'parted',\n",
       " u'became',\n",
       " u'four',\n",
       " u'heads',\n",
       " u'\\n',\n",
       " u'2:11',\n",
       " u'name',\n",
       " u'first',\n",
       " u'pison',\n",
       " u'compasseth',\n",
       " u'whole',\n",
       " u'land',\n",
       " u'havilah',\n",
       " u'gold',\n",
       " u'2:12',\n",
       " u'gold',\n",
       " u'land',\n",
       " u'good',\n",
       " u'bdellium',\n",
       " u'onyx',\n",
       " u'stone',\n",
       " u'\\n',\n",
       " u'2:13',\n",
       " u'name',\n",
       " u'second',\n",
       " u'river',\n",
       " u'gihon',\n",
       " u'compasseth',\n",
       " u'whole',\n",
       " u'land',\n",
       " u'ethiopia',\n",
       " u'\\n',\n",
       " u'2:14',\n",
       " u'name',\n",
       " u'third',\n",
       " u'river',\n",
       " u'hiddekel',\n",
       " u'goeth',\n",
       " u'toward',\n",
       " u'east',\n",
       " u'assyria',\n",
       " u'fourth',\n",
       " u'river',\n",
       " u'euphrates',\n",
       " u'\\n',\n",
       " u'2:15',\n",
       " u'lord',\n",
       " u'god',\n",
       " u'took',\n",
       " u'man',\n",
       " u'put',\n",
       " u'garden',\n",
       " u'eden',\n",
       " u'dress',\n",
       " u'keep',\n",
       " u'\\n',\n",
       " u'2:16',\n",
       " u'lord',\n",
       " u'god',\n",
       " u'commanded',\n",
       " u'man',\n",
       " u'saying',\n",
       " u'every',\n",
       " u'tree',\n",
       " u'garden',\n",
       " u'thou',\n",
       " u'mayest',\n",
       " u'freely',\n",
       " u'eat',\n",
       " u'2:17',\n",
       " u'tree',\n",
       " u'knowledge',\n",
       " u'good',\n",
       " u'evil',\n",
       " u'thou',\n",
       " u'shalt',\n",
       " u'eat',\n",
       " u'day',\n",
       " u'thou',\n",
       " u'eatest',\n",
       " u'thereof',\n",
       " u'thou',\n",
       " u'shalt',\n",
       " u'surely',\n",
       " u'die',\n",
       " u'\\n',\n",
       " u'2:18',\n",
       " u'lord',\n",
       " u'god',\n",
       " u'said',\n",
       " u'good',\n",
       " u'man',\n",
       " u'alone',\n",
       " u'make',\n",
       " u'help',\n",
       " u'meet',\n",
       " u'\\n',\n",
       " u'2:19',\n",
       " u'ground',\n",
       " u'lord',\n",
       " u'god',\n",
       " u'formed',\n",
       " u'every',\n",
       " u'beast',\n",
       " u'field',\n",
       " u'every',\n",
       " u'fowl',\n",
       " u'air',\n",
       " u'brought',\n",
       " u'unto',\n",
       " u'adam',\n",
       " u'see',\n",
       " u'would',\n",
       " u'call',\n",
       " u'whatsoever',\n",
       " u'adam',\n",
       " u'called',\n",
       " u'every',\n",
       " u'living',\n",
       " u'creature',\n",
       " u'name',\n",
       " u'thereof',\n",
       " u'\\n',\n",
       " u'2:20',\n",
       " u'adam',\n",
       " u'gave',\n",
       " u'names',\n",
       " u'cattle',\n",
       " u'fowl',\n",
       " u'air',\n",
       " u'every',\n",
       " u'beast',\n",
       " u'field',\n",
       " u'adam',\n",
       " u'found',\n",
       " u'help',\n",
       " u'meet',\n",
       " u'\\n',\n",
       " u'2:21',\n",
       " u'lord',\n",
       " u'god',\n",
       " u'caused',\n",
       " u'deep',\n",
       " u'sleep',\n",
       " u'fall',\n",
       " u'upon',\n",
       " u'adam',\n",
       " u'slept',\n",
       " u'took',\n",
       " u'one',\n",
       " u'ribs',\n",
       " u'closed',\n",
       " u'flesh',\n",
       " u'instead',\n",
       " u'thereof',\n",
       " u'2:22',\n",
       " u'rib',\n",
       " u'lord',\n",
       " u'god',\n",
       " u'taken',\n",
       " u'man',\n",
       " u'made',\n",
       " u'woman',\n",
       " u'brought',\n",
       " u'unto',\n",
       " u'man',\n",
       " u'\\n',\n",
       " u'2:23',\n",
       " u'adam',\n",
       " u'said',\n",
       " u'bone',\n",
       " u'bones',\n",
       " u'flesh',\n",
       " u'flesh',\n",
       " u'shall',\n",
       " u'called',\n",
       " u'woman',\n",
       " u'taken',\n",
       " u'man',\n",
       " u'\\n',\n",
       " u'2:24',\n",
       " u'therefore',\n",
       " u'shall',\n",
       " u'man',\n",
       " u'leave',\n",
       " u'father',\n",
       " u'mother',\n",
       " u'shall',\n",
       " u'cleave',\n",
       " u'unto',\n",
       " u'wife',\n",
       " u'shall',\n",
       " u'one',\n",
       " u'flesh',\n",
       " u'\\n',\n",
       " u'2:25',\n",
       " u'naked',\n",
       " u'man',\n",
       " u'wife',\n",
       " u'ashamed',\n",
       " u'\\n',\n",
       " u'3:1',\n",
       " u'serpent',\n",
       " u'subtil',\n",
       " u'beast',\n",
       " u'field',\n",
       " u'lord',\n",
       " u'god',\n",
       " u'made',\n",
       " u'said',\n",
       " u'unto',\n",
       " u'woman',\n",
       " u'yea',\n",
       " u'hath',\n",
       " u'god',\n",
       " u'said',\n",
       " u'ye',\n",
       " u'shall',\n",
       " u'eat',\n",
       " u'every',\n",
       " u'tree',\n",
       " u'garden',\n",
       " u'3:2',\n",
       " u'woman',\n",
       " u'said',\n",
       " u'unto',\n",
       " u'serpent',\n",
       " u'may',\n",
       " u'eat',\n",
       " u'fruit',\n",
       " u'trees',\n",
       " u'garden',\n",
       " u'3:3',\n",
       " u'fruit',\n",
       " u'tree',\n",
       " u'midst',\n",
       " u'garden',\n",
       " u'god',\n",
       " u'hath',\n",
       " u'said',\n",
       " u'ye',\n",
       " u'shall',\n",
       " u'eat',\n",
       " u'neither',\n",
       " u'shall',\n",
       " u'ye',\n",
       " u'touch',\n",
       " u'lest',\n",
       " u'ye',\n",
       " u'die',\n",
       " u'\\n',\n",
       " u'3:4',\n",
       " u'serpent',\n",
       " u'said',\n",
       " u'unto',\n",
       " u'woman',\n",
       " u'ye',\n",
       " u'shall',\n",
       " u'surely',\n",
       " u'die',\n",
       " u'3:5',\n",
       " u'god',\n",
       " u'doth',\n",
       " u'know',\n",
       " u'day',\n",
       " u'ye',\n",
       " u'eat',\n",
       " u'thereof',\n",
       " u'eyes',\n",
       " u'shall',\n",
       " u'opened',\n",
       " u'ye',\n",
       " u'shall',\n",
       " u'gods',\n",
       " u'knowing',\n",
       " u'good',\n",
       " u'evil',\n",
       " u'\\n',\n",
       " u'3:6',\n",
       " u'woman',\n",
       " u'saw',\n",
       " u'tree',\n",
       " u'good',\n",
       " u'food',\n",
       " u'pleasant',\n",
       " u'eyes',\n",
       " u'tree',\n",
       " u'desired',\n",
       " u'make',\n",
       " u'one',\n",
       " u'wise',\n",
       " u'took',\n",
       " u'fruit',\n",
       " u'thereof',\n",
       " u'eat',\n",
       " u'gave',\n",
       " u'also',\n",
       " u'unto',\n",
       " u'husband',\n",
       " u'eat',\n",
       " u'\\n',\n",
       " u'3:7',\n",
       " u'eyes',\n",
       " u'opened',\n",
       " u'knew',\n",
       " u'naked',\n",
       " u'sewed',\n",
       " u'fig',\n",
       " u'leaves',\n",
       " u'together',\n",
       " u'made',\n",
       " u'aprons',\n",
       " u'\\n',\n",
       " u'3:8',\n",
       " u'heard',\n",
       " u'voice',\n",
       " u'lord',\n",
       " u'god',\n",
       " u'walking',\n",
       " u'garden',\n",
       " u'cool',\n",
       " u'day',\n",
       " u'adam',\n",
       " u'wife',\n",
       " u'hid',\n",
       " u'presence',\n",
       " u'lord',\n",
       " u'god',\n",
       " u'amongst',\n",
       " u'trees',\n",
       " u'garden',\n",
       " u'\\n',\n",
       " u'3:9',\n",
       " u'lord',\n",
       " u'god',\n",
       " u'called',\n",
       " u'unto',\n",
       " u'adam',\n",
       " u'said',\n",
       " u'unto',\n",
       " u'art',\n",
       " u'thou',\n",
       " u'3:10',\n",
       " u'said',\n",
       " u'heard',\n",
       " u'thy',\n",
       " u'voice',\n",
       " u'garden',\n",
       " u'afraid',\n",
       " u'naked',\n",
       " u'hid',\n",
       " u'\\n',\n",
       " u'3:11',\n",
       " u'said',\n",
       " u'told',\n",
       " u'thee',\n",
       " u'thou',\n",
       " u'wast',\n",
       " u'naked',\n",
       " u'hast',\n",
       " u'thou',\n",
       " u'eaten',\n",
       " u'tree',\n",
       " u'whereof',\n",
       " u'commanded',\n",
       " u'thee',\n",
       " u'thou',\n",
       " u'shouldest',\n",
       " u'eat',\n",
       " u'3:12',\n",
       " u'man',\n",
       " u'said',\n",
       " u'woman',\n",
       " u'thou',\n",
       " u'gavest',\n",
       " u'gave',\n",
       " u'tree',\n",
       " u'eat',\n",
       " u'\\n',\n",
       " u'3:13',\n",
       " u'lord',\n",
       " u'god',\n",
       " u'said',\n",
       " u'unto',\n",
       " u'woman',\n",
       " u'thou',\n",
       " u'hast',\n",
       " u'done',\n",
       " u'woman',\n",
       " u'said',\n",
       " u'serpent',\n",
       " u'beguiled',\n",
       " u'eat',\n",
       " u'\\n',\n",
       " u'3:14',\n",
       " u'lord',\n",
       " u'god',\n",
       " u'said',\n",
       " u'unto',\n",
       " u'serpent',\n",
       " u'thou',\n",
       " ...]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_transf_books_lst = [transform_txt_file_v2(f) for f in fileid_lst]\n",
    "all_tokens = sum(all_transf_books_lst, [])\n",
    "all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_tokens_set = set(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-82f51d7cea00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokens_once\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_tokens_set\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mall_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtokens_once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#texts = [[word for word in text if word not in tokens_once] for text in texts]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tokens_once = set([word for word in all_tokens_set if all_tokens.count(word) == 1])\n",
    "tokens_once\n",
    "#texts = [[word for word in text if word not in tokens_once] for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'quixote',\n",
       " u'complete',\n",
       " u'miguel',\n",
       " u'de',\n",
       " u'cervantes',\n",
       " u'saavedra',\n",
       " u'translated',\n",
       " u'john',\n",
       " u'ormsby',\n",
       " u'contents',\n",
       " u'volume',\n",
       " u'chapter',\n",
       " u'treats',\n",
       " u'character',\n",
       " u'pursuits',\n",
       " u'famous',\n",
       " u'gentleman',\n",
       " u'quixote',\n",
       " u'la',\n",
       " u'mancha',\n",
       " u'chapter',\n",
       " u'ii',\n",
       " u'treats',\n",
       " u'first',\n",
       " u'sally',\n",
       " u'ingenious',\n",
       " u'quixote',\n",
       " u'made',\n",
       " u'home',\n",
       " u'chapter',\n",
       " u'iii',\n",
       " u'wherein',\n",
       " u'related',\n",
       " u'droll',\n",
       " u'way',\n",
       " u'quixote',\n",
       " u'dubbed',\n",
       " u'knight',\n",
       " u'chapter',\n",
       " u'iv',\n",
       " u'happened',\n",
       " u'knight',\n",
       " u'left',\n",
       " u'inn',\n",
       " u'chapter',\n",
       " u'v',\n",
       " u'narrative',\n",
       " u\"knight's\",\n",
       " u'mishap',\n",
       " u'continued',\n",
       " u'chapter',\n",
       " u'vi',\n",
       " u'diverting',\n",
       " u'important',\n",
       " u'scrutiny',\n",
       " u'curate',\n",
       " u'barber',\n",
       " u'made',\n",
       " u'library',\n",
       " u'ingenious',\n",
       " u'gentleman',\n",
       " u'chapter',\n",
       " u'vii',\n",
       " u'second',\n",
       " u'sally',\n",
       " u'worthy',\n",
       " u'knight',\n",
       " u'quixote',\n",
       " u'la',\n",
       " u'mancha',\n",
       " u'chapter',\n",
       " u'viii',\n",
       " u'good',\n",
       " u'fortune',\n",
       " u'valiant',\n",
       " u'quixote',\n",
       " u'terrible',\n",
       " u'undreamt-of',\n",
       " u'adventure',\n",
       " u'windmills',\n",
       " u'occurrences',\n",
       " u'worthy',\n",
       " u'fitly',\n",
       " u'recorded',\n",
       " u'chapter',\n",
       " u'ix',\n",
       " u'concluded',\n",
       " u'finished',\n",
       " u'terrific',\n",
       " u'battle',\n",
       " u'gallant',\n",
       " u'biscayan',\n",
       " u'valiant',\n",
       " u'manchegan',\n",
       " u'chapter',\n",
       " u'x',\n",
       " u'pleasant',\n",
       " u'discourse',\n",
       " u'passed',\n",
       " u'quixote',\n",
       " u'squire',\n",
       " u'sancho',\n",
       " u'panza',\n",
       " u'chapter',\n",
       " u'xi',\n",
       " u'befell',\n",
       " u'quixote',\n",
       " u'certain',\n",
       " u'goatherds',\n",
       " u'chapter',\n",
       " u'xii',\n",
       " u'goatherd',\n",
       " u'related',\n",
       " u'quixote',\n",
       " u'chapter',\n",
       " u'xiii',\n",
       " u'ended',\n",
       " u'story',\n",
       " u'shepherdess',\n",
       " u'marcela',\n",
       " u'incidents',\n",
       " u'chapter',\n",
       " u'xiv',\n",
       " u'wherein',\n",
       " u'inserted',\n",
       " u'despairing',\n",
       " u'verses',\n",
       " u'dead',\n",
       " u'shepherd',\n",
       " u'together',\n",
       " u'incidents',\n",
       " u'looked',\n",
       " u'chapter',\n",
       " u'xv',\n",
       " u'related',\n",
       " u'unfortunate',\n",
       " u'adventure',\n",
       " u'quixote',\n",
       " u'fell',\n",
       " u'fell',\n",
       " u'certain',\n",
       " u'heartless',\n",
       " u'yanguesans',\n",
       " u'chapter',\n",
       " u'xvi',\n",
       " u'happened',\n",
       " u'ingenious',\n",
       " u'gentleman',\n",
       " u'inn',\n",
       " u'took',\n",
       " u'castle',\n",
       " u'chapter',\n",
       " u'xvii',\n",
       " u'contained',\n",
       " u'innumerable',\n",
       " u'troubles',\n",
       " u'brave',\n",
       " u'quixote',\n",
       " u'good',\n",
       " u'squire',\n",
       " u'sancho',\n",
       " u'panza',\n",
       " u'endured',\n",
       " u'inn',\n",
       " u'misfortune',\n",
       " u'took',\n",
       " u'castle',\n",
       " u'chapter',\n",
       " u'xviii',\n",
       " u'related',\n",
       " u'discourse',\n",
       " u'sancho',\n",
       " u'panza',\n",
       " u'held',\n",
       " u'master',\n",
       " u'quixote',\n",
       " u'adventures',\n",
       " u'worth',\n",
       " u'relating',\n",
       " u'chapter',\n",
       " u'xix',\n",
       " u'shrewd',\n",
       " u'discourse',\n",
       " u'sancho',\n",
       " u'held',\n",
       " u'master',\n",
       " u'adventure',\n",
       " u'befell',\n",
       " u'dead',\n",
       " u'body',\n",
       " u'together',\n",
       " u'notable',\n",
       " u'occurrences',\n",
       " u'chapter',\n",
       " u'xx',\n",
       " u'unexampled',\n",
       " u'unheard-of',\n",
       " u'adventure',\n",
       " u'achieved',\n",
       " u'valiant',\n",
       " u'quixote',\n",
       " u'la',\n",
       " u'mancha',\n",
       " u'less',\n",
       " u'peril',\n",
       " u'ever',\n",
       " u'achieved',\n",
       " u'famous',\n",
       " u'knight',\n",
       " u'world',\n",
       " u'chapter',\n",
       " u'xxi',\n",
       " u'treats',\n",
       " u'exalted',\n",
       " u'adventure',\n",
       " u'rich',\n",
       " u'prize',\n",
       " u\"mambrino's\",\n",
       " u'helmet',\n",
       " u'together',\n",
       " u'things',\n",
       " u'happened',\n",
       " u'invincible',\n",
       " u'knight',\n",
       " u'chapter',\n",
       " u'xxii',\n",
       " u'freedom',\n",
       " u'quixote',\n",
       " u'conferred',\n",
       " u'several',\n",
       " u'unfortunates',\n",
       " u'carried',\n",
       " u'wish',\n",
       " u'go',\n",
       " u'chapter',\n",
       " u'xxiii',\n",
       " u'befell',\n",
       " u'quixote',\n",
       " u'sierra',\n",
       " u'morena',\n",
       " u'one',\n",
       " u'rarest',\n",
       " u'adventures',\n",
       " u'related',\n",
       " u'veracious',\n",
       " u'history',\n",
       " u'chapter',\n",
       " u'xxiv',\n",
       " u'continued',\n",
       " u'adventure',\n",
       " u'sierra',\n",
       " u'morena',\n",
       " u'chapter',\n",
       " u'xxv',\n",
       " u'treats',\n",
       " u'strange',\n",
       " u'things',\n",
       " u'happened',\n",
       " u'stout',\n",
       " u'knight',\n",
       " u'la',\n",
       " u'mancha',\n",
       " u'sierra',\n",
       " u'morena',\n",
       " u'imitation',\n",
       " u'penance',\n",
       " u'beltenebros',\n",
       " u'chapter',\n",
       " u'xxvi',\n",
       " u'continued',\n",
       " u'refinements',\n",
       " u'wherewith',\n",
       " u'quixote',\n",
       " u'played',\n",
       " u'part',\n",
       " u'lover',\n",
       " u'sierra',\n",
       " u'morena',\n",
       " u'chapter',\n",
       " u'xxvii',\n",
       " u'curate',\n",
       " u'barber',\n",
       " u'proceeded',\n",
       " u'scheme',\n",
       " u'together',\n",
       " u'matters',\n",
       " u'worthy',\n",
       " u'record',\n",
       " u'great',\n",
       " u'history',\n",
       " u'chapter',\n",
       " u'xxviii',\n",
       " u'treats',\n",
       " u'strange',\n",
       " u'delightful',\n",
       " u'adventure',\n",
       " u'befell',\n",
       " u'curate',\n",
       " u'barber',\n",
       " u'sierra',\n",
       " u'chapter',\n",
       " u'xxix',\n",
       " u'treats',\n",
       " u'droll',\n",
       " u'device',\n",
       " u'method',\n",
       " u'adopted',\n",
       " u'extricate',\n",
       " u'love-stricken',\n",
       " u'knight',\n",
       " u'severe',\n",
       " u'penance',\n",
       " u'imposed',\n",
       " u'upon',\n",
       " u'chapter',\n",
       " u'xxx',\n",
       " u'treats',\n",
       " u'address',\n",
       " u'displayed',\n",
       " u'fair',\n",
       " u'dorothea',\n",
       " u'matters',\n",
       " u'pleasant',\n",
       " u'amusing',\n",
       " u'chapter',\n",
       " u'xxxi',\n",
       " u'delectable',\n",
       " u'discussion',\n",
       " u'quixote',\n",
       " u'sancho',\n",
       " u'panza',\n",
       " u'squire',\n",
       " u'together',\n",
       " u'incidents',\n",
       " u'chapter',\n",
       " u'xxxii',\n",
       " u'treats',\n",
       " u'befell',\n",
       " u\"quixote's\",\n",
       " u'party',\n",
       " u'inn',\n",
       " u'chapter',\n",
       " u'xxxiii',\n",
       " u'related',\n",
       " u'novel',\n",
       " u'ill-advised',\n",
       " u'curiosity',\n",
       " u'chapter',\n",
       " u'xxxiv',\n",
       " u'continued',\n",
       " u'novel',\n",
       " u'ill-advised',\n",
       " u'curiosity',\n",
       " u'chapter',\n",
       " u'xxxv',\n",
       " u'treats',\n",
       " u'heroic',\n",
       " u'prodigious',\n",
       " u'battle',\n",
       " u'quixote',\n",
       " u'certain',\n",
       " u'skins',\n",
       " u'red',\n",
       " u'wine',\n",
       " u'brings',\n",
       " u'novel',\n",
       " u'ill-advised',\n",
       " u'curiosity',\n",
       " u'close',\n",
       " u'chapter',\n",
       " u'xxxvi',\n",
       " u'treats',\n",
       " u'curious',\n",
       " u'incidents',\n",
       " u'occurred',\n",
       " u'inn',\n",
       " u'chapter',\n",
       " u'xxxvii',\n",
       " u'continued',\n",
       " u'story',\n",
       " u'famous',\n",
       " u'princess',\n",
       " u'micomicona',\n",
       " u'droll',\n",
       " u'adventures',\n",
       " u'chapter',\n",
       " u'xxxviii',\n",
       " u'treats',\n",
       " u'curious',\n",
       " u'discourse',\n",
       " u'quixote',\n",
       " u'delivered',\n",
       " u'arms',\n",
       " u'letters',\n",
       " u'chapter',\n",
       " u'xxxix',\n",
       " u'wherein',\n",
       " u'captive',\n",
       " u'relates',\n",
       " u'life',\n",
       " u'adventures',\n",
       " u'chapter',\n",
       " u'xl',\n",
       " u'story',\n",
       " u'captive',\n",
       " u'continued',\n",
       " u'chapter',\n",
       " u'xli',\n",
       " u'captive',\n",
       " u'still',\n",
       " u'continues',\n",
       " u'adventures',\n",
       " u'chapter',\n",
       " u'xlii',\n",
       " u'treats',\n",
       " u'took',\n",
       " u'place',\n",
       " u'inn',\n",
       " u'several',\n",
       " u'things',\n",
       " u'worth',\n",
       " u'knowing',\n",
       " u'chapter',\n",
       " u'xliii',\n",
       " u'wherein',\n",
       " u'related',\n",
       " u'pleasant',\n",
       " u'story',\n",
       " u'muleteer',\n",
       " u'together',\n",
       " u'strange',\n",
       " u'things',\n",
       " u'came',\n",
       " u'pass',\n",
       " u'inn',\n",
       " u'chapter',\n",
       " u'xliv',\n",
       " u'continued',\n",
       " u'unheard-of',\n",
       " u'adventures',\n",
       " u'inn',\n",
       " u'chapter',\n",
       " u'xlv',\n",
       " u'doubtful',\n",
       " u'question',\n",
       " u\"mambrino's\",\n",
       " u'helmet',\n",
       " u'pack-saddle',\n",
       " u'finally',\n",
       " u'settled',\n",
       " u'adventures',\n",
       " u'occurred',\n",
       " u'truth',\n",
       " u'earnest',\n",
       " u'chapter',\n",
       " u'xlvi',\n",
       " u'end',\n",
       " u'notable',\n",
       " u'adventure',\n",
       " u'officers',\n",
       " u'holy',\n",
       " u'brotherhood',\n",
       " u'great',\n",
       " u'ferocity',\n",
       " u'worthy',\n",
       " u'knight',\n",
       " u'quixote',\n",
       " u'chapter',\n",
       " u'xlvii',\n",
       " u'strange',\n",
       " u'manner',\n",
       " u'quixote',\n",
       " u'la',\n",
       " u'mancha',\n",
       " u'carried',\n",
       " u'away',\n",
       " u'enchanted',\n",
       " u'together',\n",
       " u'remarkable',\n",
       " u'incidents',\n",
       " u'chapter',\n",
       " u'xlviii',\n",
       " u'canon',\n",
       " u'pursues',\n",
       " u'subject',\n",
       " u'books',\n",
       " u'chivalry',\n",
       " u'matters',\n",
       " u'worthy',\n",
       " u'wit',\n",
       " u'chapter',\n",
       " u'xlix',\n",
       " u'treats',\n",
       " u'shrewd',\n",
       " u'conversation',\n",
       " u'sancho',\n",
       " u'panza',\n",
       " u'held',\n",
       " u'master',\n",
       " u'quixote',\n",
       " u'chapter',\n",
       " u'l',\n",
       " u'shrewd',\n",
       " u'controversy',\n",
       " u'quixote',\n",
       " u'canon',\n",
       " u'held',\n",
       " u'together',\n",
       " u'incidents',\n",
       " u'chapter',\n",
       " u'li',\n",
       " u'deals',\n",
       " u'goatherd',\n",
       " u'told',\n",
       " u'carrying',\n",
       " u'quixote',\n",
       " u'chapter',\n",
       " u'lii',\n",
       " u'quarrel',\n",
       " u'quixote',\n",
       " u'goatherd',\n",
       " u'together',\n",
       " u'rare',\n",
       " u'adventure',\n",
       " u'penitents',\n",
       " u'expenditure',\n",
       " u'sweat',\n",
       " u'brought',\n",
       " u'happy',\n",
       " u'conclusion',\n",
       " u\"translator's\",\n",
       " u'preface',\n",
       " u'translation',\n",
       " u'considerable',\n",
       " u'reluctance',\n",
       " u'abandoned',\n",
       " u'favour',\n",
       " u'present',\n",
       " u'undertaking',\n",
       " u'long',\n",
       " u'favourite',\n",
       " u'project',\n",
       " u'new',\n",
       " u'edition',\n",
       " u\"shelton's\",\n",
       " u'quixote',\n",
       " u'become',\n",
       " u'somewhat',\n",
       " u'scarce',\n",
       " u'book',\n",
       " u'some--and',\n",
       " u'confess',\n",
       " u'one--for',\n",
       " u\"shelton's\",\n",
       " u'racy',\n",
       " u'old',\n",
       " u'version',\n",
       " u'defects',\n",
       " u'charm',\n",
       " u'modern',\n",
       " u'translation',\n",
       " u'however',\n",
       " u'skilful',\n",
       " u'correct',\n",
       " u'could',\n",
       " u'possess',\n",
       " u'shelton',\n",
       " u'inestimable',\n",
       " u'advantage',\n",
       " u'belonging',\n",
       " u'generation',\n",
       " u'cervantes',\n",
       " u'quixote',\n",
       " u'vitality',\n",
       " u'contemporary',\n",
       " u'could',\n",
       " u'feel',\n",
       " u'cost',\n",
       " u'dramatic',\n",
       " u'effort',\n",
       " u'see',\n",
       " u'things',\n",
       " u'cervantes',\n",
       " u'saw',\n",
       " u'anachronism',\n",
       " u'language',\n",
       " u'put',\n",
       " u'spanish',\n",
       " u'cervantes',\n",
       " u'english',\n",
       " u'shakespeare',\n",
       " u'shakespeare',\n",
       " u'likely',\n",
       " u'knew',\n",
       " u'book',\n",
       " u'may',\n",
       " u'carried',\n",
       " u'home',\n",
       " u'saddle-bags',\n",
       " u'stratford',\n",
       " u'one',\n",
       " u'last',\n",
       " u'journeys',\n",
       " u'mulberry',\n",
       " u'tree',\n",
       " u'new',\n",
       " u'place',\n",
       " u'joined',\n",
       " u'hands',\n",
       " u'kindred',\n",
       " u'genius',\n",
       " u'pages',\n",
       " u'soon',\n",
       " u'made',\n",
       " u'plain',\n",
       " u'hope',\n",
       " u'even',\n",
       " u'moderate',\n",
       " u'popularity',\n",
       " u'shelton',\n",
       " u'vain',\n",
       " u'fine',\n",
       " u'old',\n",
       " u'crusted',\n",
       " u'english',\n",
       " u'would',\n",
       " u'doubt',\n",
       " u'relished',\n",
       " u'minority',\n",
       " u'would',\n",
       " u'minority',\n",
       " u'warmest',\n",
       " u'admirers',\n",
       " u'must',\n",
       " u'admit',\n",
       " u'satisfactory',\n",
       " u'representative',\n",
       " u'cervantes',\n",
       " u'translation',\n",
       " u'first',\n",
       " u'part',\n",
       " u'hastily',\n",
       " u'made',\n",
       " u'never',\n",
       " u'revised',\n",
       " u'freshness',\n",
       " u'vigour',\n",
       " u'also',\n",
       " u'full',\n",
       " u'measure',\n",
       " u'faults',\n",
       " u'hasty',\n",
       " u'production',\n",
       " u'often',\n",
       " u'literal--barbarously',\n",
       " u'literal',\n",
       " u'frequently--but',\n",
       " u'often',\n",
       " u'loose',\n",
       " u'evidently',\n",
       " u'good',\n",
       " u'colloquial',\n",
       " u'knowledge',\n",
       " u'spanish',\n",
       " u'apparently',\n",
       " u'much',\n",
       " u'never',\n",
       " u'seems',\n",
       " u'occur',\n",
       " u'translation',\n",
       " u'word',\n",
       " u'suit',\n",
       " u'every',\n",
       " u'case',\n",
       " u'often',\n",
       " u'said',\n",
       " u'satisfactory',\n",
       " u'translation',\n",
       " u'quixote',\n",
       " u'familiar',\n",
       " u'original',\n",
       " u'savours',\n",
       " u'truism',\n",
       " u'platitude',\n",
       " u'say',\n",
       " u'truth',\n",
       " u'thoroughly',\n",
       " u'satisfactory',\n",
       " u'translation',\n",
       " u'quixote',\n",
       " u'english',\n",
       " u'language',\n",
       " u'spanish',\n",
       " u'idioms',\n",
       " u'utterly',\n",
       " u'unmanageable',\n",
       " u'untranslatable',\n",
       " u'words',\n",
       " u'numerous',\n",
       " u'enough',\n",
       " u'doubt',\n",
       " u'superabundant',\n",
       " u'rather',\n",
       " u'sententious',\n",
       " u'terseness',\n",
       " u'humour',\n",
       " u'book',\n",
       " u'owes',\n",
       " u'flavour',\n",
       " u'peculiar',\n",
       " u'spanish',\n",
       " u'best',\n",
       " u'distantly',\n",
       " u'imitated',\n",
       " u'tongue',\n",
       " u'history',\n",
       " u'english',\n",
       " u'translations',\n",
       " u'quixote',\n",
       " u'instructive',\n",
       " u\"shelton's\",\n",
       " u'first',\n",
       " u'language',\n",
       " u'made',\n",
       " u'apparently',\n",
       " u'1608',\n",
       " u'published',\n",
       " u'till',\n",
       " u'1612',\n",
       " u'course',\n",
       " u'first',\n",
       " u'part',\n",
       " u'asserted',\n",
       " u'second',\n",
       " u'published',\n",
       " u'1620',\n",
       " u'work',\n",
       " u'shelton',\n",
       " u'nothing',\n",
       " u'support',\n",
       " u'assertion',\n",
       " u'save',\n",
       " u'fact',\n",
       " u'less',\n",
       " u'spirit',\n",
       " u'less',\n",
       " u'generally',\n",
       " u'understand',\n",
       " u'go',\n",
       " u'first',\n",
       " u'would',\n",
       " u'natural',\n",
       " u'first',\n",
       " u'work',\n",
       " u'young',\n",
       " u'man',\n",
       " u'writing',\n",
       " u'currente',\n",
       " u'calamo',\n",
       " u'second',\n",
       " u'middle-aged',\n",
       " u'man',\n",
       " u'writing',\n",
       " u'bookseller',\n",
       " u'hand',\n",
       " u'closer',\n",
       " u'literal',\n",
       " u'style',\n",
       " u'translations',\n",
       " u'mistranslations',\n",
       " u'occur',\n",
       " u'extremely',\n",
       " u'unlikely',\n",
       " u'new',\n",
       " u'translator',\n",
       " u'would',\n",
       " u'suppressing',\n",
       " u'name',\n",
       " u'allowed',\n",
       " u'shelton',\n",
       " u'carry',\n",
       " u'credit',\n",
       " u'1687',\n",
       " u'john',\n",
       " u'phillips',\n",
       " u\"milton's\",\n",
       " u'nephew',\n",
       " u'produced',\n",
       " u'quixote',\n",
       " u'made',\n",
       " u'english',\n",
       " u'says',\n",
       " u'according',\n",
       " u'humour',\n",
       " u'modern',\n",
       " u'language',\n",
       " u'quixote',\n",
       " u'much',\n",
       " u'translation',\n",
       " u'travesty',\n",
       " u'travesty',\n",
       " u'coarseness',\n",
       " u'vulgarity',\n",
       " u'buffoonery',\n",
       " u'almost',\n",
       " u'unexampled',\n",
       " u'even',\n",
       " u'literature',\n",
       " u'day',\n",
       " u'ned',\n",
       " u\"ward's\",\n",
       " u'life',\n",
       " u'notable',\n",
       " u'adventures',\n",
       " u'quixote',\n",
       " u'merrily',\n",
       " u'translated',\n",
       " u'hudibrastic',\n",
       " u'verse',\n",
       " u'1700',\n",
       " u'scarcely',\n",
       " u'reckoned',\n",
       " u'translation',\n",
       " u'serves',\n",
       " u'show',\n",
       " u'light',\n",
       " u'quixote',\n",
       " u'regarded',\n",
       " u'time',\n",
       " u'illustration',\n",
       " u'may',\n",
       " u'found',\n",
       " u'version',\n",
       " u'published',\n",
       " u'1712',\n",
       " u'peter',\n",
       " u'motteux',\n",
       " u'recently',\n",
       " u'combined',\n",
       " u'tea-dealing',\n",
       " u'literature',\n",
       " u'described',\n",
       " u'translated',\n",
       " u'original',\n",
       " u'several',\n",
       " u'hands',\n",
       " u'spanish',\n",
       " u'flavour',\n",
       " u'entirely',\n",
       " u'evaporated',\n",
       " u'manipulation',\n",
       " u'several',\n",
       " u'hands',\n",
       " u'flavour',\n",
       " u'hand',\n",
       " u'distinctly',\n",
       " u'franco-cockney',\n",
       " u'anyone',\n",
       " u'compares',\n",
       " u'carefully',\n",
       " u'original',\n",
       " u'little',\n",
       " u'doubt',\n",
       " u'concoction',\n",
       " u'shelton',\n",
       " u'french',\n",
       " u'filleau',\n",
       " u'de',\n",
       " u'saint',\n",
       " u'martin',\n",
       " u'eked',\n",
       " u'borrowings',\n",
       " u'phillips',\n",
       " u'whose',\n",
       " u'mode',\n",
       " u'treatment',\n",
       " u'adopts',\n",
       " u'sure',\n",
       " u'decent',\n",
       " u'decorous',\n",
       " u'treats',\n",
       " u'quixote',\n",
       " u'fashion',\n",
       " u'comic',\n",
       " u'book',\n",
       " u'cannot',\n",
       " u'made',\n",
       " u'comic',\n",
       " u'attempt',\n",
       " u'improve',\n",
       " u'humour',\n",
       " u'quixote',\n",
       " u'infusion',\n",
       " u'cockney',\n",
       " u'flippancy',\n",
       " u'facetiousness',\n",
       " u\"motteux's\",\n",
       " u'operators',\n",
       " u'merely',\n",
       " u'impertinence',\n",
       " u'like',\n",
       " u'larding',\n",
       " u'sirloin',\n",
       " u'prize',\n",
       " u'beef',\n",
       " u'absolute',\n",
       " u'falsification',\n",
       " u'spirit',\n",
       " u'book',\n",
       " u'proof',\n",
       " u'uncritical',\n",
       " u'way',\n",
       " u'quixote',\n",
       " u'generally',\n",
       " u'read',\n",
       " u'worse',\n",
       " u'worthless',\n",
       " u'translation--worthless',\n",
       " u'failing',\n",
       " u'represent',\n",
       " u'worse',\n",
       " u'worthless',\n",
       " u'misrepresenting--should',\n",
       " u'favoured',\n",
       " u'effect',\n",
       " u'however',\n",
       " u'bringing',\n",
       " u'translation',\n",
       " u'undertaken',\n",
       " u'executed',\n",
       " u'different',\n",
       " u'spirit',\n",
       " u'charles',\n",
       " u'jervas',\n",
       " u'portrait',\n",
       " u'painter',\n",
       " u'friend',\n",
       " u'pope',\n",
       " u'swift',\n",
       " u'arbuthnot',\n",
       " u'gay',\n",
       " u'jervas',\n",
       " u'allowed',\n",
       " u'little',\n",
       " u'credit',\n",
       " u'work',\n",
       " u'indeed',\n",
       " u'may',\n",
       " u'said',\n",
       " u'none',\n",
       " u'known',\n",
       " u'world',\n",
       " u'general',\n",
       " u\"jarvis's\",\n",
       " u'published',\n",
       " u'death',\n",
       " u'printers',\n",
       " u'gave',\n",
       " u'name',\n",
       " u'according',\n",
       " u'current',\n",
       " u'pronunciation',\n",
       " u'day',\n",
       " u'freely',\n",
       " u'used',\n",
       " u'freely',\n",
       " u'abused',\n",
       " u'translations',\n",
       " u'seen',\n",
       " u'far',\n",
       " u'editions',\n",
       " u'admitted',\n",
       " u'hands',\n",
       " u'far',\n",
       " u'faithful',\n",
       " u'yet',\n",
       " u'nobody',\n",
       " u'seems',\n",
       " u'good',\n",
       " u'word',\n",
       " u'say',\n",
       " u'author',\n",
       " u'jervas',\n",
       " u'doubt',\n",
       " u'prejudiced',\n",
       " u'readers',\n",
       " u'preface',\n",
       " u'among',\n",
       " u'many',\n",
       " u'true',\n",
       " u'words',\n",
       " u'shelton',\n",
       " u'stevens',\n",
       " u'motteux',\n",
       " u'rashly',\n",
       " u'unjustly',\n",
       " u'charges',\n",
       " u'shelton',\n",
       " u'translated',\n",
       " u'spanish',\n",
       " ...]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_l = transform_txt_file_v2(f)\n",
    "b_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this goes to slow - see this post for frequency filtering (if time):\n",
    "#https://stackoverflow.com/questions/24688116/how-to-filter-out-words-with-low-tf-idf-in-a-corpus-with-gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20 s, sys: 15 s, total: 35 s\n",
      "Wall time: 64.1 s\n",
      "tokens set done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-d4dbe81969a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"tokens set done\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtokens_once\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_tokens_set\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mb_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"part two done\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-d4dbe81969a9>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m((word,))\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"tokens set done\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtokens_once\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_tokens_set\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mb_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"part two done\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_tokens_set = set(b_l)\n",
    "%time\n",
    "print \"tokens set done\"\n",
    "tokens_once = set(word for word in all_tokens_set if b_l.count(word) <= 1)\n",
    "%time\n",
    "print \"part two done\"\n",
    "print [word for word in b_l if word not in tokens_once]\n",
    "%time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import ldamodel\n",
    "from gensim.models import LdaMulticore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-7937757739b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mldamodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLdaModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdictionary2\u001b[0m\u001b[0;34m,\u001b[0m                         \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rachelbrynsvold/anaconda/lib/python2.7/site-packages/gensim/models/ldamodel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLdaState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_terms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m100.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_terms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpElogbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirichlet_expectation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msstats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;31m# if a training corpus was provided, start estimating the model right away\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rachelbrynsvold/anaconda/lib/python2.7/site-packages/gensim/matutils.pyc\u001b[0m in \u001b[0;36mdirichlet_expectation\u001b[0;34m(alpha)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpsi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpsi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpsi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpsi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# keep the same precision as input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lda = ldamodel.LdaModel(corpus=corpus4,alpha='auto', id2word=dictionary2, \\\n",
    "                        num_topics=100, update_every=0, passes=20)\n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = 'lda.model'\n",
    "lda.save(outputs_dir + name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process PoolWorker-4:\n",
      "  File \"/Users/rachelbrynsvold/anaconda/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Process PoolWorker-1:\n",
      "Process PoolWorker-2:\n",
      "Process PoolWorker-5:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rachelbrynsvold/anaconda/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/Users/rachelbrynsvold/anaconda/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rachelbrynsvold/anaconda/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/Users/rachelbrynsvold/anaconda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "  File \"/Users/rachelbrynsvold/anaconda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/Users/rachelbrynsvold/anaconda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/rachelbrynsvold/anaconda/lib/python2.7/multiprocessing/pool.py\", line 97, in worker\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/rachelbrynsvold/anaconda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/Users/rachelbrynsvold/anaconda/lib/python2.7/multiprocessing/pool.py\", line 97, in worker\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    initializer(*initargs)\n",
      "  File \"/Users/rachelbrynsvold/anaconda/lib/python2.7/multiprocessing/pool.py\", line 97, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/Users/rachelbrynsvold/anaconda/lib/python2.7/multiprocessing/pool.py\", line 97, in worker\n",
      "  File \"/Users/rachelbrynsvold/anaconda/lib/python2.7/site-packages/gensim/models/ldamulticore.py\", line 274, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "    initializer(*initargs)\n",
      "  File \"/Users/rachelbrynsvold/anaconda/lib/python2.7/site-packages/gensim/models/ldamulticore.py\", line 274, in worker_e_step\n",
      "    initializer(*initargs)\n",
      "  File \"/Users/rachelbrynsvold/anaconda/lib/python2.7/multiprocessing/queues.py\", line 115, in get\n",
      "  File \"/Users/rachelbrynsvold/anaconda/lib/python2.7/site-packages/gensim/models/ldamulticore.py\", line 274, in worker_e_step\n",
      "  File \"/Users/rachelbrynsvold/anaconda/lib/python2.7/site-packages/gensim/models/ldamulticore.py\", line 274, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "    self._rlock.acquire()\n",
      "  File \"/Users/rachelbrynsvold/anaconda/lib/python2.7/multiprocessing/queues.py\", line 115, in get\n",
      "KeyboardInterrupt\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/Users/rachelbrynsvold/anaconda/lib/python2.7/multiprocessing/queues.py\", line 115, in get\n",
      "    self._rlock.acquire()\n",
      "  File \"/Users/rachelbrynsvold/anaconda/lib/python2.7/multiprocessing/queues.py\", line 117, in get\n",
      "    self._rlock.acquire()\n",
      "KeyboardInterrupt\n",
      "    res = self._recv()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-bebc4d622523>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlda_multi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLdaMulticore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdictionary4\u001b[0m\u001b[0;34m,\u001b[0m                         \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rachelbrynsvold/anaconda/lib/python2.7/site-packages/gensim/models/ldamulticore.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, workers, chunksize, passes, batch, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, random_state, minimum_probability, minimum_phi_value, per_word_topics)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_every\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mgamma_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimum_probability\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mminimum_probability\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             minimum_phi_value=minimum_phi_value, per_word_topics=per_word_topics)\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rachelbrynsvold/anaconda/lib/python2.7/site-packages/gensim/models/ldamodel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0muse_numpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunks_as_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_numpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_dir_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rachelbrynsvold/anaconda/lib/python2.7/site-packages/gensim/models/ldamulticore.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, corpus, chunks_as_numpy)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;31m# wait for all outstanding jobs to finish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mqueue_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m                 \u001b[0mprocess_result_queue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreallen\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlencorpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rachelbrynsvold/anaconda/lib/python2.7/site-packages/gensim/models/ldamulticore.pyc\u001b[0m in \u001b[0;36mprocess_result_queue\u001b[0;34m(force)\u001b[0m\n\u001b[1;32m    224\u001b[0m                     \u001b[0mqueue_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                     \u001b[0mmerged_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforce\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmerged_new\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mqueue_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumdocs\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mupdateafter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpass_\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                     \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lda_multi = LdaMulticore(corpus=corpus4, id2word=dictionary4, \\\n",
    "                        num_topics=100, passes=20, workers=4)\n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = 'lda_multi.model'\n",
    "lda_multi.save(outputs_dir + name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print lda_multi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the topics and their most significant terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lda.show_topics()\n",
    "#also lda.show_topics() - what is difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given document (in bow format), see most relevant topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda.get_document_topics(dictionary2.doc2bow(transform_txt_file_v2('1080-clean.txt')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given term in vocab, see what topics are most likely/relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda.get_term_topics(100, minimum_probability=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverse of above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda.get_topic_terms(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for tup in lda.get_topic_terms(0):\n",
    "    print dictionary2[tup[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Document alignment\n",
    "#softmax - zeroing - zero out all not in the top2 alignment\n",
    "    #manually creat label from top word\n",
    "    #need to include logic to use two topics if below certain threshhold\n",
    "#projection - \n",
    "#cos sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
